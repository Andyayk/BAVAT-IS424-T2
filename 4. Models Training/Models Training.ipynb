{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import all libraries and reading explored data into Dataframe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.197888Z",
     "start_time": "2018-11-02T13:49:12.900261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget                 float64\n",
      "revenue                float64\n",
      "weekday                float64\n",
      "day                    float64\n",
      "month                  float64\n",
      "year                   float64\n",
      "runtime                float64\n",
      "vote_average           float64\n",
      "vote_count             float64\n",
      "weighted_rating        float64\n",
      "bin                    float64\n",
      "log_revenue            float64\n",
      "log_budget             float64\n",
      "log_runtime            float64\n",
      "log_vote_count         float64\n",
      "log_vote_average       float64\n",
      "log_weighted_rating    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>weighted_rating</th>\n",
       "      <th>bin</th>\n",
       "      <th>log_revenue</th>\n",
       "      <th>log_budget</th>\n",
       "      <th>log_runtime</th>\n",
       "      <th>log_vote_count</th>\n",
       "      <th>log_vote_average</th>\n",
       "      <th>log_weighted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>0.00</td>\n",
       "      <td>5300.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2018.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13591</th>\n",
       "      <td>45.00</td>\n",
       "      <td>136.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1091.00</td>\n",
       "      <td>6.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.91</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.49</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18416</th>\n",
       "      <td>0.00</td>\n",
       "      <td>15200.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2006.00</td>\n",
       "      <td>93.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>13.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.53</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15598</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4496912.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>209.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13693</th>\n",
       "      <td>0.00</td>\n",
       "      <td>17543400.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1990.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>124.00</td>\n",
       "      <td>6.99</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.82</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       budget     revenue  weekday   day  month    year  runtime  \\\n",
       "7863     0.00     5300.00     5.00  9.00  11.00 2018.00    90.00   \n",
       "13591   45.00      136.00     5.00 11.00   4.00 1997.00    89.00   \n",
       "18416    0.00    15200.00     7.00  1.00   1.00 2006.00    93.00   \n",
       "15598    0.00  4496912.00     2.00  1.00   7.00 2008.00    76.00   \n",
       "13693    0.00 17543400.00     5.00 16.00   3.00 1990.00   102.00   \n",
       "\n",
       "       vote_average  vote_count  weighted_rating  bin  log_revenue  \\\n",
       "7863           5.10        5.00             7.00 1.00         8.58   \n",
       "13591          4.90     1091.00             6.91 1.00         4.91   \n",
       "18416          5.70       13.00             7.00 1.00         9.63   \n",
       "15598          6.80      209.00             7.00 3.00        15.32   \n",
       "13693          5.80      124.00             6.99 4.00        16.68   \n",
       "\n",
       "       log_budget  log_runtime  log_vote_count  log_vote_average  \\\n",
       "7863         0.00         4.50            1.61              1.63   \n",
       "13591        3.81         4.49            6.99              1.59   \n",
       "18416        0.00         4.53            2.56              1.74   \n",
       "15598        0.00         4.33            5.34              1.92   \n",
       "13693        0.00         4.62            4.82              1.76   \n",
       "\n",
       "       log_weighted_rating  \n",
       "7863                  1.95  \n",
       "13591                 1.93  \n",
       "18416                 1.95  \n",
       "15598                 1.95  \n",
       "13693                 1.95  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import io\n",
    "\n",
    "#General libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Libraries for data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Libraries for data pre-processing (Log Loss)\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#For Decision Tree implementation\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#For KNN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#For AdaBoost implementation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#For Random Forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#For Baseline implementation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#For Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#For Ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#Settings\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "sns.set()\n",
    "\n",
    "def printModelAccuracy(y_test, y_pred):\n",
    "    # Find the confusion matrix of the result\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=[1, 2, 3, 4, 5]), \\\n",
    "        index=['true:1', 'true:2', 'true:3', 'true:4', 'true:5'], \n",
    "        columns=['pred:1', 'pred:2', 'pred:3', 'pred:4', 'pred:5'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Find the accuracy and F1 score of the result\n",
    "    asr = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Accuracy:\", asr)\n",
    "    print(\"F1:\", f1)\n",
    "    \"\"\"\n",
    "    # Log loss\n",
    "    score = log_loss(y_test, y_pred)\n",
    "    print(\"Log Loss:\", score)\n",
    "    \"\"\"\n",
    "    \n",
    "# Read from dataframe\n",
    "df = pd.read_pickle(\"explored_data\")\n",
    "df = df.replace([np.inf, -np.inf, np.nan], 0) #removing infinite/nan values\n",
    "\n",
    "# Check the columns using dtypes\n",
    "print(df.dtypes)\n",
    "# Randomly sample 5 records with .sample(5)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor column in df.columns:\\n    if df[column].dtype == type(object):\\n        #Create the label encoder\\n        le = preprocessing.LabelEncoder()\\n        #Convert the non numeric data to numeric\\n        df[column] = le.fit_transform(df[column])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree in SKLearn don't take in string well. So we use a label encoder to change that string to a numeric value\n",
    "\"\"\"\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == type(object):\n",
    "        #Create the label encoder\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        #Convert the non numeric data to numeric\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Find out the number of records per revenue bin. </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:55:55.489674Z",
     "start_time": "2018-11-02T13:55:55.227099Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bin     n\n",
      "0 1.00  3502\n",
      "1 2.00  3500\n",
      "2 3.00  3502\n",
      "3 4.00  3502\n",
      "4 5.00  3505\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAG7CAYAAAAG43g6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XtAk/XiP/D3YICieG0TQ76ek10oLK1UxPqONAUMBoiWeIP0ZGiKqX31pJJ4v4XxzRtldlU6ini4xBeHmmUqWIgekRNZx4RUDCYigrDBtuf3hz+HhIbysD1M3q9/Yp89bG8+Eu89d5kgCAKIiIhEsJM6ABER2T6WCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBOySStWrEBwcDCCg4PRt29f+Pn5mR/rdDqLv/+GDRvwzTff3PXyWVlZCA4OtmAi6/nXv/6FJUuWSB2DWhm51AGImiM6Otr89bBhwxAbG4snn3zSau+fnZ2NJ554wmrv15r88ssvKC0tlToGtTIsE7ovJSYmYvfu3airq0NFRQWmTZuGsWPHYvfu3UhJScH169fRpUsXbNu2DWvXrsW3334LFxcXPPnkkygqKsJnn32GiooKrFy5Ev/5z39QV1eH5557DvPmzUNCQgJ++uknrFq1CjKZDC+++GKD9969ezc+/fRT2Nvbo3v37li7dm2D58+ePYvly5ejpqYGJSUl8PT0RFxcHBwdHREXF4eDBw/CwcEBXbt2xdq1a/HAAw/ccfxWVVVVWLZsGU6dOgU7Ozv4+flh9uzZuHbtGpYuXYozZ84AAIYOHYo333wTAODp6YmcnBx06tQJBoPB/Dg/Px+bNm3Cgw8+iP/85z8wGo1YtmwZFAoFNm/ejMrKSixatAgrV6604L8i2RSByMYNHTpUyMvLMz+urKwUXnnlFaG8vFwQBEHIyckRBgwYIAiCICQmJgpeXl5CZWWlIAiCsGPHDmHSpEmCXq8X9Hq9EBERIURERAiCIAjz5s0TEhISBEEQBIPBIMydO1f45JNPBEEQhLCwMGH//v2Nspw+fVrw9vYWLl26JAiCIGzbtk1YsmSJcPToUSEoKEgQBEFYtWqVkJ6eLgiCINTW1gojR44U9u/fL/z222/CwIEDBb1eLwiCIGzdulX4+uuv7zj+R8uXLxfeeustwWg0Cnq9XggLCxNycnKEuXPnCqtXrxYEQRB0Op0QEREhbNu2TairqxMeffRRoaKiQhAEocHjo0ePCk888YTw008/CYIgCB9++KEQHh5unsPp06ff478S3e+4ZkL3nY4dOyI+Ph7ffPMNCgsLUVBQgOrqavPzHh4e6NixIwDg0KFDGDVqFBwdHQEAr7zyChITE83P/fjjj9i1axcAQKfTmZe7k+zsbKhUKri6ugIA/va3vwG4sc/kpvnz5+Po0aPYunUrCgsLUVZWhurqavTs2RN9+vRBaGgoVCoVVCoVBg8eDIPBcNvxP8rKykJMTAzs7Ozg6OiIf/zjHwCAGTNmICkpCQDg5OSEsWPHYufOnYiIiPjTn6VXr1547LHHANxYg8nIyPjT5altY5nQfefixYsYP348wsLCMGDAAPj6+uLIkSPm552dnc1f29vbQ7jl8nT29vbmrw0GAzZt2oS//OUvAICKigrY2f35MStyuRwymcz8uKamBr///nuDZWbPng2ZTAZ/f38MGzYMFy5cgCAIkMvl+PLLL5GXl4fs7GysWLECw4YNw9y5c+84fit7e/sG711cXIz27dvDaDQ2GBcEAQaDwTx28+evq6tr8Hrt2rUzfy2TyRrME9Ef8Wguuu+cPn0aCoUC06ZNw/PPP49vvvkGJpPptsu+8MILSEtLQ21tLQwGA5KTk81/ZJ9//nl89tlnEAQBer0ekZGR5k/7crm80R9fABg8eDAOHz4MrVYLAPjyyy+xfv36BsscOXIEUVFReOmll2A0GnH69GmYTCb8+9//RlBQEB555BFMmzYN4eHhOH369B3H/2jIkCFITk6GIAiora3FzJkzceLECTz//PPYsWMHAECv1yMxMRFDhgyBvb09OnfujPz8fABAenr6Xc2vvb09DAbDXS1LbQfXTOi+o1Kp8M9//hP+/v6QyWTw8vJC586d8dtvvzVadsyYMSgsLERISAg6dOiABx980FwmMTExWLFiBdRqNerq6vD8889jypQpAG4cQfbuu++itra2wSG/jz/+ON566y3z5q0ePXpg1apV+OWXX8zLzJ07F9OmTYOzszNcXFwwaNAgFBUVYdSoURg+fDhCQ0Ph7OyMdu3aYfHixfDw8Ljt+B9FRUVh5cqVCAoKgtFoRGBgIF588UU8/fTTWL58OQIDA1FXVweVSoWpU6cCuHFU3DvvvIMuXbrgueeeQ7du3Zqc36effhrx8fGYNWsWNmzYcA//MnQ/kwlcd6U27LvvvkNFRQXUajUAYOnSpejUqRPmzJkjcTIi28IyoTbt0qVLWLBgAa5cuQKj0YjHH38cS5YsMe+gJ6K7wzIhIiLRuAOeiIhEY5kQEZFoLBMiIhLtvj80uLz8OkwmaXcLde/eEWVlVZJmaC04F/U4F/U4F/Wkngs7Oxm6du1wz99335eJySRIXiY3c9ANnIt6nIt6nIt6tjgX3MxFRESisUyIiEg0lgkREYl23+8zISKyBqPRgPJyLQyGWlGvU1pqd8cLk7YkOzt7tG/fER07dm5wVenmYpkQEbWA8nIt2rVzRocOrqL+OMvldjAYLFsmgiDAaDSgsvIqysu16NZNKfo1uZmLiKgFGAy16NChU4t8yrc0mUwGudwBXbp0R22trkVek2VCRNRCbKFIbiWT2QFomcOQWSZERCQa95kQEVmAS6f2aOfU8n9idXoDKq/VtPjrisUyISKygHZOcqjfSm3x1/1qfTAqW/xVxbNombz//vvIzMyETCbDmDFjMHnyZCxYsAC5ublo3749AGDmzJkYMWIEsrKysHr1auj1eowcOdJ8p7uCggIsWrQI169fx4ABA7B06VLI5exAIqI/c+LEcWzf/inatWuHwsJz6NPnYcTErISDg4NF3s9i+0x++OEHHDt2DGlpadizZw+2b9+OX3/9Ffn5+dixYwdSU1ORmpqKESNGQKfTYeHChdiyZQsyMjKQn5+PQ4cOAQDmzZuHxYsXIzMzE4IgIDEx0VKRiYjuK/n5eZgzZz4SEpJQUvI7vv8+22LvZbEyGTRoEL744gvI5XKUlZXBaDSiXbt2KC4uxsKFC6FWq7FhwwaYTCbk5eWhd+/ecHd3h1wuh1qthkajwcWLF6HT6dC/f38AQGhoKDQajaUiExHdV/761z5QKnvAzs4OvXv/FZWV1yz2XhbdXuTg4IANGzbgk08+gb+/PwwGAwYPHoyYmBi4uLggMjISSUlJcHZ2hkKhMH+fUqlESUkJSktLG4wrFAqUlJTcU4bu3cXdy7u2zghHB3tRrwEACoWL5BnEMhlqYSd3FP06YuaipTKIVWusg6O9+M0Fon4vWiiDWKbaWtg5Svx70UIZxCgttYO9vR2scXSwXH7n9QBBAGQywN7eDk5OTuZl7exuZPvj99rZ2Ymae3Mm0a/QhFmzZmHq1KmYNm0asrOzsXnzZvNzkyZNQkpKCvz8/Bocny0IAmQyGUwm023H70VZWZWoyzkrFC4W2Yl2L75aHwytVvpdbgqFC35dOVrSDA8t2tNq5uKVXdMlzZA4Nr7VzMXRYGl/L55Llf734sbfK6D4fAUANOueIHfr5nvczoPunWEwmGA0miAIgvlsekG4cTuOP55dbzKZGsydnZ2sWR/CLVYmZ8+eRW1tLR5//HG0b98evr6+yMjIQJcuXeDn5wfgxg8nl8vh6uoKrVZr/l6tVgulUtlo/PLly1AqxZ/2T0RkadU1dfhqfbBFXrc1sliZXLhwARs2bMA//vEPAMDXX3+NgQMHYtWqVRg8eDCcnZ2xa9cujBo1Cv369cO5c+dQVFSEXr16IT09HaNHj4abmxucnJyQm5uLZ599FqmpqVCpVJaKTETUYs79om16IQt65pkBeOaZAebHixYtsej7WaxMfHx8kJeXh5CQENjb28PX1xczZ85E165dMW7cOBgMBvj6+iIwMBAAsGbNGkRFRUGv18PHxwf+/v4AgNjYWERHR6Oqqgqenp4IDw+3VGQiImomi+4ziYqKQlRUVIOxCRMmYMKECY2W9fb2RlpaWqNxDw8PJCUlWSwjERGJx2tzERG1EEGwrXu3t2RelgkRUQuws7OH0WiQOsY9qaurhb19y2ygYpkQEbWA9u074tq1cptYOxEEAbW1ely9qkXHjl1a5DV5kSsiohbQsWNn1NSUo+LaJWnva1J89a5u+2tvL4eLS1e0b98y58OwTIiIWoBMJkPv3r3x+YbTkuZYvD5QkhM4uZmLiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0SxaJu+//z5eeuklBAQE4NNPPwUAZGVlQa1Ww9fXF3FxceZlCwoKEBoaCj8/PyxatAgGgwEAUFxcjAkTJsDf3x/Tp0/H9evXLRmZiIiawWJl8sMPP+DYsWNIS0vDnj17sH37dvz0009YuHAhtmzZgoyMDOTn5+PQoUMAgHnz5mHx4sXIzMyEIAhITEwEACxduhTjx4+HRqNB3759sWXLFktFJiKiZrJYmQwaNAhffPEF5HI5ysrKYDQace3aNfTu3Rvu7u6Qy+VQq9XQaDS4ePEidDod+vfvDwAIDQ2FRqNBXV0dcnJy4Ofn12CciIhaF7klX9zBwQEbNmzAJ598An9/f5SWlkKhUJifVyqVKCkpaTSuUChQUlKC8vJydOzYEXK5vMH4vejevWPL/DASUyhcpI7QanAu6nEu6nEu6kkxFxYtEwCYNWsWpk6dimnTpqGwsBAymcz8nCAIkMlkMJlMtx2/+d9b/fFxU8rKqmAyCc3O31p+QbXaSqkjcC5uwbmox7modz/MhZ2drFkfwi22mevs2bMoKCgAALRv3x6+vr74/vvvodVqzctotVoolUq4uro2GL98+TKUSiW6deuGyspKGI3GBssTEVHrYrEyuXDhAqKjo1FbW4va2lp8/fXXCAsLw7lz51BUVASj0Yj09HSoVCq4ubnByckJubm5AIDU1FSoVCo4ODhgwIAByMjIAACkpKRApVJZKjIRETWTxTZz+fj4IC8vDyEhIbC3t4evry8CAgLQrVs3REVFQa/Xw8fHB/7+/gCA2NhYREdHo6qqCp6enggPDwcAxMTE4O2330Z8fDx69uyJ9957z1KRiYiomSy6zyQqKgpRUVENxry9vZGWltZoWQ8PDyQlJTUad3Nzw/bt2y2WkYiIxOMZ8EREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItFYJkREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItFYJkREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItFYJkREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItFYJkREJBrLhIiIRGOZEBGRaBYtk02bNiEgIAABAQFYt24dAGDBggXw9fVFcHAwgoODsX//fgBAVlYW1Go1fH19ERcXZ36NgoIChIaGws/PD4sWLYLBYLBkZCIiagaLlUlWVhaOHDmC5ORkpKSk4N///jf279+P/Px87NixA6mpqUhNTcWIESOg0+mwcOFCbNmyBRkZGcjPz8ehQ4cAAPPmzcPixYuRmZkJQRCQmJhoqchERNRMFisThUKBt99+G46OjnBwcECfPn1QXFyM4uJiLFy4EGq1Ghs2bIDJZEJeXh569+4Nd3d3yOVyqNVqaDQaXLx4ETqdDv379wcAhIaGQqPRWCoyERE1k9xSL/zII4+Yvy4sLMTevXuRkJCAH374ATExMXBxcUFkZCSSkpLg7OwMhUJhXl6pVKKkpASlpaUNxhUKBUpKSu4pR/fuHcX/MK2AQuEidYRWg3NRj3NRj3NRT4q5sFiZ3PTLL78gMjIS8+fPx0MPPYTNmzebn5s0aRJSUlLg5+cHmUxmHhcEATKZDCaT6bbj96KsrAomk9Ds/K3lF1SrrZQ6AufiFpyLepyLevfDXNjZyZr1IdyiO+Bzc3Px6quv4q233sKoUaNw5swZZGZmmp8XBAFyuRyurq7QarXmca1WC6VS2Wj88uXLUCqVloxMRETNYLEyuXTpEmbMmIHY2FgEBAQAuFEeq1atQkVFBerq6rBr1y6MGDEC/fr1w7lz51BUVASj0Yj09HSoVCq4ubnByckJubm5AIDU1FSoVCpLRSYiomay2Gaujz/+GHq9HmvWrDGPhYWF4fXXX8e4ceNgMBjg6+uLwMBAAMCaNWsQFRUFvV4PHx8f+Pv7AwBiY2MRHR2NqqoqeHp6Ijw83FKRiYiomSxWJtHR0YiOjr7tcxMmTGg05u3tjbS0tEbjHh4eSEpKavF8RETUcngGPBERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0Zosk7Nnz2L37t0QBAGzZ8/G8OHDcezYMWtkIyIiG9FkmcTExMDJyQnffvstSkpKsHLlSsTFxVkjGxER2Ygmy0Sv1yMoKAhHjhzByJEj4eXlhbq6OmtkIyIiG9FkmdTW1uLy5cv49ttvMWTIEFy+fBl6vd4a2YiIyEY0WSZjx47F0KFD8eyzz+Lhhx/GmDFjEBERYY1sRERkI+RNLTB+/HiEhYXBzu5G7yQnJ6Nr164WD0ZERLajyTWT69evY8WKFYiIiMDVq1cRFxeH69evWyMbERHZiCbLZMWKFXBxcUFZWRmcnJxQVVWFxYsXWyMbERHZiCbLpKCgAHPmzIFcLkf79u0RGxuLgoICa2QjIiIb0WSZ3NxXcpPRaGw0RkREbVuTO+AHDhyId999FzqdDocPH0ZCQgK8vLyskY2IiGxEk6sY//M//wNnZ2e4uLggLi4Ojz32GObPn2+NbEREZCOaXDNxcHDAjBkzMGPGDGvkISIiG3THMnnzzTfx/vvvQ61W3/b5r776ymKhiIjIttyxTKZOnQoAeOedd6wWhoiIbNMdy6Rv374AgJ07d+KVV17B4MGDrRaKiIhsS5M74AcOHIj33nsPI0aMwIcffgitVmuNXEREZEOaLJNx48YhMTERH3zwASoqKhAWFnbXO+M3bdqEgIAABAQEYN26dQCArKwsqNVq+Pr6NrgvSkFBAUJDQ+Hn54dFixbBYDAAAIqLizFhwgT4+/tj+vTpvJQLEVErdNdnH+p0OtTW1kIQBNjb2ze5fFZWFo4cOYLk5GSkpKTg3//+N9LT07Fw4UJs2bIFGRkZyM/Px6FDhwAA8+bNw+LFi5GZmQlBEJCYmAgAWLp0KcaPHw+NRoO+fftiy5YtzfxRiYjIUposk08//RRqtRpz585Fjx49kJiYiA0bNjT5wgqFAm+//TYcHR3h4OCAPn36oLCwEL1794a7uzvkcjnUajU0Gg0uXrwInU6H/v37AwBCQ0Oh0WhQV1eHnJwc+Pn5NRgnIqLWpcnzTPLz8xEdHX3PZ70/8sgj5q8LCwuxd+9eTJw4EQqFwjyuVCpRUlKC0tLSBuMKhQIlJSUoLy9Hx44dIZfLG4zfi+7dO97T8q2VQuEidYRWg3NRj3NRj3NRT4q5aLJM1q9fj1OnTmHTpk2oq6vDc889h0GDBt31G/zyyy+IjIzE/PnzYW9vj8LCQvNzgiBAJpPBZDJBJpM1Gr/531v98XFTysqqYDIJ9/Q9t2otv6BabaXUETgXt+Bc1ONc1Lsf5sLOTtasD+FNbuZKTU3FrFmzUFFRgevXr+Ott94y789oSm5uLl599VW89dZbGDVqFFxdXRscDabVaqFUKhuNX758GUqlEt26dUNlZSWMRmOD5YmIqHW5q30mu3fvxqJFixAdHY2kpCR88cUXTb7wpUuXMGPGDMTGxiIgIAAA0K9fP5w7dw5FRUUwGo1IT0+HSqWCm5sbnJyckJubC+BGgalUKjg4OGDAgAHIyMgAAKSkpEClUon5eYmIyAKa3MxlMpkarA306NHjri5B//HHH0Ov12PNmjXmsbCwMKxZswZRUVHQ6/Xw8fGBv78/ACA2NhbR0dGoqqqCp6cnwsPDAQAxMTF4++23ER8fj549e+K999675x+SiIgsq8ky6dKlCw4cOIDhw4cDAA4cOIDOnTs3+cLR0dGIjo6+7XNpaWmNxjw8PJCUlNRo3M3NDdu3b2/y/YiISDpNlsk777yDN954A8uXL4dMJoNcLsfmzZutkY2IiGxEk2XyyCOPQKPRoLCwEEajEQ899JD5UF0iIiLgT8rk008/ve340aNHAQCTJ0+2TCIiIrI5dyyTtWvX4oEHHsCQIUPu6vIpRETUdt2xTD7//HOkpKTgxIkTePHFFxEaGoqHH37YmtmIiMhG3LFMvLy84OXlBZ1Oh3379mHVqlW4fv06goODERgYiE6dOlkzJxERtWJNnjDSrl07BAUF4ZNPPsH69euh0Wjw/PPPWyMbERHZiLs6LCsvLw9paWnIzMzEo48+ipUrV1o6FxER2ZA7lsmFCxeQlpaGtLQ0ODk5ITg4GHv27OG1sYiIqJE7lsnw4cPx4IMPIigoCE888QQA4F//+pf5eV9fX8unIyIim3DHMhk4cCCAG1f+vXkBxptkMhnLhIiIzO5YJrweFhER3a27vgc8ERHRnbBMiIhItDuWyalTp6yZg4iIbNgdy2TJkiUAgIiICGtlISIiG3XHHfAGgwFTpkzBjz/+iGnTpjV6/oMPPrBoMCIish13LJOPPvoIx44dw7lz5+Dn52fNTEREZGPuWCaurq4ICQlBz5494eXlhYsXL8JgMKB3797WzEdERDagyWtz9ejRAwEBASgtLYXJZELXrl3x4Ycfok+fPtbIR0RENqDJQ4OXL1+O1157DTk5OcjNzcX06dOxdOlSa2QjIiIb0WSZlJWVYdSoUebHo0ePRnl5uUVDERGRbWmyTIxGI65evWp+fOXKFYsGIiIi29PkPpOJEydi7NixGDlyJGQyGTIyMnjuCRERNdBkmYwdOxb/9V//hSNHjsBkMiEmJgZDhgyxRjYiIrIRd3WnRW9vb3h7e1s6CxER2She6JGIiERjmRARkWgsEyIiEq1ZZbJx48aWzkFERDasWWUiCEJL5yAiIhvWrDKZNWtWS+cgIiIb1uShwSaTCR9//DG+++47GAwGPPfcc5g2bRrk8rs6qpiIiNqAJtdM1q9fj2PHjiEiIgKTJ0/GyZMnsW7dOmtkIyIiG9Hk6sXhw4exZ88eODg4AABeeOEFBAUFYeHChRYPR0REtqHJNRNBEMxFAgCOjo4NHjelqqoKgYGBuHDhAgBgwYIF8PX1RXBwMIKDg7F//34AQFZWFtRqNXx9fREXF2f+/oKCAoSGhsLPzw+LFi2CwWC46/cmIiLraLJMPDw8sGrVKvz22284f/48Vq9ejUcfffSuXvzUqVMYN24cCgsLzWP5+fnYsWMHUlNTkZqaihEjRkCn02HhwoXYsmULMjIykJ+fj0OHDgEA5s2bh8WLFyMzMxOCICAxMbF5PykREVlMk2USExODiooKhIWF4eWXX8aVK1fwzjvv3NWLJyYmIiYmBkqlEgBQU1OD4uJiLFy4EGq1Ghs2bIDJZEJeXh569+4Nd3d3yOVyqNVqaDQaXLx4ETqdDv379wcAhIaGQqPRiPhxiYjIEprcZ9KxY0esXbu2WS++cuXKBo8vX76MwYMHIyYmBi4uLoiMjERSUhKcnZ2hUCjMyymVSpSUlKC0tLTBuEKhQElJSbOyEBGR5dyxTBYsWHDHb5LJZFi1atU9v5m7uzs2b95sfjxp0iSkpKTAz88PMpnMPC4IAmQyGUwm023H70X37h3vOWdrpFC4SB2h1eBc1ONc1ONc1JNiLu5YJo888kijsfLycnz++edwc3Nr1pudOXMGhYWF8PPzA3CjHORyOVxdXaHVas3LabVaKJXKRuOXL182bzK7W2VlVTCZmn/Gfmv5BdVqK6WOwLm4BeeiHuei3v0wF3Z2smZ9CL9jmUyZMqXB46ysLPz973+HWq1GdHT0vSfEjfJYtWoVBg8eDGdnZ+zatQujRo1Cv379cO7cORQVFaFXr15IT0/H6NGj4ebmBicnJ+Tm5uLZZ59FamoqVCpVs96biIgsp8l9JgaDAevXr0dycjKWLl1qXqtoDg8PD7z++usYN24cDAYDfH19ERgYCABYs2YNoqKioNfr4ePjA39/fwBAbGwsoqOjUVVVBU9PT4SHhzf7/YmIyDL+tEwKCwsxd+5cdOjQASkpKXB1dW3Wmxw8eND89YQJEzBhwoRGy3h7eyMtLa3RuIeHB5KSkpr1vkREZB13PDR4z549eOWVVzBixAhs37692UVCRET3vzuumSxatAh2dnbYunUrPvroI/P4zSOqTpw4YZWARETU+t2xTL7++mtr5iAiIht2xzJp7uG/RETU9vAe8EREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItFYJkREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItFYJkREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItFYJkREJBrLhIiIRGOZEBGRaCwTIiISjWVCRESisUyIiEg0lgkREYnGMiEiItEsWiZVVVUIDAxfwKzaAAAchElEQVTEhQsXAABZWVlQq9Xw9fVFXFycebmCggKEhobCz88PixYtgsFgAAAUFxdjwoQJ8Pf3x/Tp03H9+nVLxiUiomayWJmcOnUK48aNQ2FhIQBAp9Nh4cKF2LJlCzIyMpCfn49Dhw4BAObNm4fFixcjMzMTgiAgMTERALB06VKMHz8eGo0Gffv2xZYtWywVl4iIRLBYmSQmJiImJgZKpRIAkJeXh969e8Pd3R1yuRxqtRoajQYXL16ETqdD//79AQChoaHQaDSoq6tDTk4O/Pz8GowTEVHrI7fUC69cubLB49LSUigUCvNjpVKJkpKSRuMKhQIlJSUoLy9Hx44dIZfLG4zfq+7dOzbzJ2hdFAoXqSO0GpyLepyLepyLelLMhcXK5I9MJhNkMpn5sSAIkMlkdxy/+d9b/fHx3Sgrq4LJJDQ7d2v5BdVqK6WOwLm4BeeiHuei3v0wF3Z2smZ9CLfa0Vyurq7QarXmx1qtFkqlstH45cuXoVQq0a1bN1RWVsJoNDZYnoiIWh+rlUm/fv1w7tw5FBUVwWg0Ij09HSqVCm5ubnByckJubi4AIDU1FSqVCg4ODhgwYAAyMjIAACkpKVCpVNaKS0RE98Bqm7mcnJywZs0aREVFQa/Xw8fHB/7+/gCA2NhYREdHo6qqCp6enggPDwcAxMTE4O2330Z8fDx69uyJ9957z1pxiYjoHli8TA4ePGj+2tvbG2lpaY2W8fDwQFJSUqNxNzc3bN++3aL5iIhIPJ4BT0REorFMiIhINJYJERGJxjIhIiLRWCZERCQay4SIiERjmRARkWgsEyIiEo1lQkREorFMiIhINJYJERGJxjIhIiLRWCZERCQay4SIiERjmRARkWgsEyIiEo1lQkREorFMiIhINJYJERGJxjIhIiLRWCZERCQay4SIiERjmRARkWgsEyIiEo1lQkREorFMiIhINJYJERGJxjIhIiLRWCZERCQay4SIiERjmRARkWgsEyIiEo1lQkREorFMiIhINJYJERGJJpfiTSdNmoQrV65ALr/x9suWLcNvv/2G+Ph4GAwGREREYMKECQCArKwsrF69Gnq9HiNHjsScOXOkiExERH/C6mUiCAIKCwvxzTffmMukpKQEc+bMwT//+U84OjoiLCwMXl5e6NWrFxYuXIjt27ejZ8+eiIyMxKFDh+Dj42Pt2ERE9CesXia//vorAGDKlCm4evUqXnnlFXTo0AGDBw9Gly5dAAB+fn7QaDQYNGgQevfuDXd3dwCAWq2GRqNhmRARtTJWL5Nr167B29sb77zzDurq6hAeHo6RI0dCoVCYl1EqlcjLy0NpaWmj8ZKSknt6v+7dO7ZYdikpFC5SR2g1OBf1OBf1OBf1pJgLq5fJ008/jaefftr8eMyYMVi9ejWmT59uHhMEATKZDCaTCTKZrNH4vSgrq4LJJDQ7b2v5BdVqK6WOwLm4BeeiHuei3v0wF3Z2smZ9CLf60VzHjx9Hdna2+bEgCHBzc4NWqzWPabVaKJVKuLq63naciIhaF6uXSWVlJdatWwe9Xo+qqiokJyfj3XffRXZ2Nq5cuYKamhrs27cPKpUK/fr1w7lz51BUVASj0Yj09HSoVCprRyYioiZYfTPX0KFDcerUKYSEhMBkMmH8+PF49tlnMWfOHISHh6Ourg5jxozBU089BQBYs2YNoqKioNfr4ePjA39/f2tHJiKiJkhynsns2bMxe/bsBmNqtRpqtbrRst7e3khLS7NWNCIiagaeAU9ERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBMiIhKNZUJERKKxTIiISDSWCRERiWYTZfLVV1/hpZdegq+vLxISEqSOQ0REfyCXOkBTSkpKEBcXh3/+859wdHREWFgYvLy88PDDD0sdjYiI/r9Wv2aSlZWFwYMHo0uXLnB2doafnx80Go3UsYiI6Batfs2ktLQUCoXC/FipVCIvL++uv9/OTiY6g7Jre9GvIVZL/BwtQd5Z0fRCFtZa5kLh3E3qCK1mLpyU/L24qbON/71o7vfKBEEQmv2uVhAfHw+9Xo/Zs2cDABITE5Gfn49ly5ZJnIyIiG5q9Zu5XF1dodVqzY+1Wi2USqWEiYiI6I9afZkMGTIE2dnZuHLlCmpqarBv3z6oVCqpYxER0S1a/T6THj16YM6cOQgPD0ddXR3GjBmDp556SupYRER0i1a/z4SIiFq/Vr+Zi4iIWj+WCRERicYyISIi0VgmREQkGsuEiIhEY5kQEZFoLBOyqPLy8kZjBw8elCCJ9P74c5eWliIqKkqiNEQtq9WftGiLDh48iGHDhpkfl5aWYvny5di4caOEqaQxefJkfPLJJ+jWrRu0Wi2WL1+O//znPw3mp62Ii4uD0WjEiBEjkJCQgM2bN2PChAlSx7IqDw8PyGQy3O70NplMhoKCAglSSaO4uPhPn3/wwQetlKRl8KRFC1Cr1Zg1a1ajPxozZsyQOprVZWZmIj4+HiEhIdi2bRvGjRuH119/HQ4ODlJHs7qysjJERkbCaDSiW7duWLx4MXr37i11LJLIsGHD/rRYv/76awlSNR/LxAL4R6Oho0ePIioqCvHx8fDy8pI6jtXl5OSYv7527RpiYmIwdepUPPHEEwCAgQMHShXN6nbt2oWxY8di06ZNt31+5syZVk5ELYWbuVrQrX80pk+fjpiYGISEhKC0tBSlpaVt6o/GzU9dACAIAgRBwIwZM9C5c2cAsLlPXWJs2LChweO//vWvOHDgAA4cOACZTIYvvvhComTWx8+u9TZu3IioqCgsWLDgts+vXr3ayonE4ZpJC5o0adIdn2trfzQuXrz4p8+7ublZKQlR63Rz32pycvJtnx81apSVE4nDMrGgqqoqyOVytGvXTuookjh79iwyMzPx+++/w87ODkqlEv/93/+NJ598UupoVlVTU4MtW7ZAo9E0mAuVSoXZs2fDxcVF6ohW9/nnn2Pz5s2orKwEcGONpa3tgL9VVVUVrl271mCMO+DbsIULF2LVqlUoKSnB7NmzcfbsWQDAU089hZUrV6JHjx4SJ7SehIQEJCYmws/Pz3zbZa1Wi3379iEoKAhTpkyROKH1zJgxA56enggNDW0wF8nJyThx4gQ++ugjiRNa37Bhw7Bjxw6b+4NpCWvXrkViYiK6dOkCoL5YbW5TsEAtJiQkRBAEQZg+fbrwj3/8wzyenJwshIeHSxVLEr6+vkJ1dXWj8erqasHPz0+CRNIZOXLkHZ8LCAiwYpLW429/+5ug1+uljtEqjBgxQqiqqpI6hmjcAW8BFy5cQFhYmPlxSEgIPv74YwkTWZ9cLofBYGg0rtPp2txhwd26dcPevXvh5+cHO7sb5wkLgoCMjAx07dpV4nTSCA8Ph1qtRr9+/WBvb28et7Wdzi3hscceQ21tLTp06CB1FFFYJi2ouLgYW7duRZcuXXDgwAEMHz4cgiAgMzPT5n9R7tW0adMQEhICb29vKBQKyGQylJaW4tixY5gzZ47U8azq3XffxdKlSxEdHW3eP1JZWYmBAwdi7dq1EqeTxvr166FWq3kgBoDg4GD4+vri0UcfbVCstnbADveZtKCcnBzk5+fj9OnT6NSpE5YsWYIPPvgA+/fvx7p169CnTx+pI1pVSUkJsrOzUVpaCpPJBFdXV3h7e7epfUe3MhgMKC8vh8lkQvfu3SGXt93Pci+//DJ2794tdYxWISAgAFOnTm20/2jQoEESJWoelglZRF5eHp566ikAQFZWFg4dOgQHBwf4+vqax9sKk8mExMTERkdz+fj4YOLEiW1usx8ArFmzBgCgUqka/Pxt6Vysm8LCwrBz506pY4jGMmlBlZWV2LZtG7p06YKXXnoJb775Jn7++Wc8++yzWLFiRZv6RD5q1CgkJycjISEBO3fuxJgxYyAIApKTk/Hyyy9j4sSJUke0mnfeeQcmkwmjRo2CUqmEIAjQarVIS0tDdXU1YmNjpY5odbc7J6utnYt107Jly6DVahsVa0hIiISp7h3LpAW98cYb6NOnD0pKSvDDDz9g+vTpCAoKQkZGBvbv348PPvhA6ohWc7NMgoOD8dlnn5l3NFdVVWHMmDHQaDQSJ7Qef3//O/68L730EjIyMqycqPVo6+diAbhvzoBvuxttLeDChQvYsmUL6urq8MILL2Ds2LEAgNGjR2PHjh0Sp7Mug8EAk8mELl26wNHR0Tzu6OhoPqKprejQoUODzX43nTx5ss0dmMFzsRpbvXo1DAYDzp49C7lcbrP7VlkmLUgul+PXX3/FQw89hE8//dQ8/uOPP5qvU9VWdOnSBS+88AIAYPny5VizZg2ys7Px7rvvwt/fX9pwVrZixQrMnz8fer2+wZFtTk5ObW4T180z3JcuXYrg4GDzIfQpKSmYP38+Pv/8cynjWdVrr72Gbdu24eeff8aMGTPQoUMHmEwmCIKA9957D4888ojUEe+NJGe33KdycnIEX19fwWAwmMf2798vqFQqITc3V8Jk0jl79qxw8uRJQRAE4fjx48I333wjbSAJXbx4UTh58qSQm5srXLx4Ueo4krh5Yq9arW70XGBgoLXjSOrmXERERAjffvutefz7778XxowZI1WsZmtb2xssbMCAAQgLC0NmZqZ5rLq6GhMnTsQzzzwjYTJpnD17Fq6urujfvz9++OEH/Otf/2qz28azs7NRUlKC/v374+TJk1i2bBk2b96M2tpaqaNZ1R/PxQJunMCp0Wja3Ca/m65evQofHx/z40GDBkGn00mYqHlYJi1MpVJh27Zt5sfbt2/H0KFDJUwkjW3btuGNN97A1atXsWPHDqxYsQJXrlzBunXr8OGHH0odz6rWrVuHuLg4LF++HLNmzUJeXh7GjRuH0tJSLFu2TOp4VrVp0yY4ODjggQcewJEjRwAAH374IT766COsXLlS4nTWVVRUhJiYGLRv3958aHBFRQU+/vhj8zXcbAn3mbSwPn36oGvXrjhx4gRkMhk6deqEhx9+WOpYVpeUlISUlBS0b98ee/bswY4dO9CpUyfodDqEhIQgMjJS6ohWc/jwYaSmpqK2thYvvPACDh8+DAcHB6hUKgQHB0sdz6oGDhzY6FySadOmYdq0aRIlkk56ejry8/PRqVMnXL58GQDw1Vdf4dSpUzZ3JBfAMrGIiIgI7NixAzKZDBEREVLHkYSzszNMJhMAoHv37uYjuuzt7dvcmd+CIKCyshLV1dWoqalBVVUVunbtCp1Oh7q6OqnjSW7ixIlt7mhH4MYl5h988EH4+vqax0JDQ232HCyeZ2IharUa9vb2SElJkTqKJBITE/HZZ59h/PjxKCsrw8mTJzF06FAcOHAA//3f/43XX39d6ohWk5qailWrVkEQBMyaNQt79uyBt7c3srOzERAQgNdee03qiFbz4osvNhorKSkxHxJsc5ddb2E3z8+yRSwTC8nPz4dMJoOnp6fUUSRz/PhxaDQaFBUVwWg04oEHHsDQoUMxcuRIqaNZnU6ng9FoRIcOHXDmzBkcOXIEHh4eeO6556SOZlXffvst1q1bh5kzZ6Jfv34QBAGRkZHYunUrgLZ1B84nn3zSfGVt4f/fw+Tmn2NbvFEYy4SIrKqsrAyLFi1C37598cYbb2D06NE2+2lcjB9//BErVqzAq6++at7UFRISYrNbM3g0FxFZVffu3fHBBx+gc+fOiIiIQE1NjdSRJPHEE0/gk08+QVZWFhYsWIDr16/b9MnNXDMhIsn8/PPPyMzMRFRUlNRRJHXw4EHEx8ejoqIC+/btkzpOs7Stw2pIEj///DN++OEHGAwGeHl54fHHH5c6kmQOHTqEY8eOmedi+PDhUkeS1KOPPopHH31U6hiSO3XqFDw8PGz69gzczEUWlZKSgjfeeAPnz59HcXExZsyYgaSkJKljSeKjjz7Cpk2b0LNnT/Tq1QsffPAB4uPjpY5FErt69SoyMzORm5sLPz8/qeM0GzdzkUX98RL0V65cQXh4ONLT0yVOZn1qtRq7d+82X1KmpqYGoaGh2Lt3r8TJSEo3j2S7yVYPm+dmLrIok8lkLhIA6Natm03vZBRDEIQG1yZzcnJqcydw3lRTU4ONGzfi2LFjMBqN8PLywuzZs+Hs7Cx1NKsyGAzYs2cPdu3aBQAYO3Ys/va3vzW4F7ytsF+yZMkSqUPQ/evEiRPIyclBjx49UFZWhg8//BAdO3ZscNZvW/Hrr7+a10zOnTuH//3f/8Vjjz0GlUoldTSrW7x4MWQyGWbNmoURI0bg9OnTyMzMbHO/FxkZGTAYDAgMDES7du1w5swZVFdX47HHHpM62j3jZi6yKJ1OZ/4EKggCvLy8MHPmzDZ5hVhBEPDll1/i+++/hyAIGDx4MMLCwmzyU6hYQUFBSEtLazDWFu86efz4cfNlVQDg0qVLOH/+PAYNGiRxsnvXNtexyWr27t2LefPmNRhLSEjAhAkTJEokna1btyIyMrLBz/7ee+9h7ty5EqaShiAIuHbtGjp16gQAuHbtWpss1QEDBjR43LNnT/Ts2VOiNOKwTMgiPvvsM1RVVWHnzp24ePGiedxoNOKrr75qU2USGxuLsrIyHDx4EIWFheZxo9GIU6dOtckyefXVV/Hyyy+bb89w8OBBTJ06VeJUJAbLhCziL3/5C/Lz8xuNOzo6Ys2aNRIkko6vry/Onj2LY8eONdh8YW9vjzfeeEPCZNIZPXo0+vbti+PHj8NkMmHjxo02uZ+A6nGfCVnU2bNn0adPH6ljtAqVlZVwcXGROkarEBUVhY0bNzYYi4iIaFP3gL/fsEyIyGpmzpyJgoIClJaWQqlUmseNRiNcXV3Ndxwk28MyISKrqaqqwtWrV7Fy5UpER0ebx+VyObp3795mz7u5H7BMyKLKy8sbnLQI3NjZOmzYMIkSSef8+fNwd3dvMLZ9+3ZMmjRJokRELYfX5iKLmjx5Mq5cuQIA0Gq1mDVrFmJjYyVOJY3XXnsNRUVFAIAzZ87g5ZdfbvN3FqT7B9dMyKIyMzMRHx+PkJAQbNu2DePGjcPrr78OBwcHqaNZ3YkTJxAdHY0hQ4Zg3759mDt3LkJCQqSORdQiWCZkcUePHkVUVBTi4+Ph5eUldRxJ/fTTT3jttdewfv36Nj0Xf9zUWVpaiuXLlzc6wotsB8uELGLYsGHmCzoKgoDy8nLY29ujc+fOANCmNu94eHg0uL/3rWzxXt8tQa1Wm6/LlZCQgM2bN2PChAmYMWOG1NGomVgmZBG3nvV+O25ublZKQq1RWVkZIiMjYTQa0a1bNyxevBi9e/eWOhaJwDIhizhw4ID5LoK7d+/Gd999B7lcjhEjRuCll16SOJ31HT58GBqNBr///jvs7OygVCrh4+PT5q6Sm5OTY/762rVriImJwdSpU/HEE08AAAYOHChVNBKJZUIWMWrUKCQnJ2Pjxo04fvw4Jk2aBEEQsGvXLnh6emLOnDlSR7Sa999/H3l5eQgKCoJSqYQgCNBqtUhPT8fDDz+Mv//971JHtJo/OwxaJpPhiy++sGIaakksE7KIm2USFBSE3bt3w8nJCQBQV1eHwMBAZGZmSpzQevz8/LB3717Y2TU8Et9oNCIwMJB3WqT7Ak83JYuorq7G5cuX4erqiqqqKnOZ6HS6NneWs5OTE37//XfzPStuKi4uhqOjo0SppFFTU4MtW7Y02uSnUqkwe/ZsXrvMhnHNhCxiwYIFyM/Px6VLl+Dt7Y2NGzdi3759WLVqFSIjIzFu3DipI1pNVlYWFi1ahL/85S9QKBSQyWQoLS1FYWEhVq9ejcGDB0sd0WpmzJgBT09PhIaGQqFQALhxMmtycjJOnDiBjz76SOKE1FwsE7IonU4HrVYLd3d3/PzzzxAEoU1ealyv1yMvLw+lpaUwmUzo2bMnnnrqqTa3ZvJnd1MMDAxEenq6lRNRS+HlVMhiCgsLUVFRAXd3d+zevRuJiYk4e/as1LGs7sCBA3BycsKAAQNQXV2NzMxMJCQk4MCBA1JHs7pu3bph7969MJlM5jFBEPB///d/ja7hRraFayZkEZ999hm2b98Ok8mEwYMH49KlSxgxYgQOHjyIZ555pk2dnMYj2+pdunQJS5cuRU5Ojnn/SGVlJQYOHIjFixc32q9EtoNlQhahVquRlJSEy5cvIzAwEMeOHYOTkxNqa2sxZswYpKWlSR3RanhkW2MGgwHl5eUwmUy89Px9gv+CZBEmkwmOjo5wc3PDlClTzH9AgRuHxLYlPLKtnslkQmJi4m1P4Jw4cWKbvADo/YL7TMgifH19MXHiRBiNRkRFRQG4cZHD8ePHY+TIkRKns65nnnkGkydPxokTJ7BkyRIAwL59+6BWqzFx4kRpw1lZTEwMTp8+jZkzZ2Lr1q2Ij4/HzJkzce7cOSxYsEDqeCQCN3ORxeTk5DS4PMavv/6K8+fPw8fHR8JU0uGRbYC/vz80Gs1tn/uzI72o9eOaCVnMH6+z9NBDD7XZIjl8+DBqa2vh7u6OlJQU7Ny5E/n5+VLHsroOHTogLy+v0fjJkyfRoUMHCRJRS+GaCZGFrVy5EgUFBYiLi0NCQgLy8vIwfPhwfPfdd+jVq1eDe6Hf7woKCjB//nzo9foGJ3A6OTkhNja2za2p3U9YJkQWFhAQgLS0NNjb22PUqFHYtWsXHB0d2/S1uYqLi80ncLq6uvKQ4PsAN3MRWVi7du1QVlYGAHB1dUV1dTWAG9epamtHcwFAdnY2SkpK0L9/f5w8eRLLli3D5s2bUVtbK3U0EoFrJkQWdvDgQSxZsgQBAQEwGAw4duwYvL29ceTIEbz22msIDQ2VOqLVrFu3DsePH4fBYECvXr0gk8kQGhqKgwcPwmg0YsWKFVJHpGZimRBZwfnz53HgwAEUFRXBaDTigQcewNChQ/HUU09JHc2q1Go1UlNTUVtbixdeeAGHDx+Gg4MDBEFAcHBwmzqZ9X7T9taxiSTg7u6OyZMnSx1DcoIgoLKyEtXV1aipqUFVVRW6du0KnU6Huro6qeORCCwTIrKaqVOnwtfXF4IgYN68eZgyZQq8vb2RnZ2N0aNHSx2PROBmLiKyKp1OB6PRiA4dOuDMmTM4cuQIPDw88Nxzz0kdjURgmRARkWg8NJiIiERjmRARkWgsEyIL+f777xEYGNho/P3330dKSooEiYgsh0dzEVnZm2++KXUEohbHNRMiC6qursasWbMQHByMSZMm4dy5c3j77bfx8ccfAwCefPJJbNy4EWFhYRg2bBi+/PJLiRMTNQ/LhMiCLl26hFdffRWpqakIDAzE/PnzGzxfW1uLrl27YufOndiwYQNWr14NvV4vUVqi5mOZEFnQY489hmeeeQbAjXvB5+fno7KyssEyL774IgDA09MTtbW15gtBEtkSlgmRBdnZNfxfTCaTNbpS8M17wstkMgA3LjlCZGtYJkQWdObMGRQUFAAAdu3ahWeffRbt27eXOBVRy2OZEFnQQw89hE2bNiEoKAgHDx7EmjVrpI5EZBG8nAoREYnGNRMiIhKNZUJERKKxTIiISDSWCRERicYyISIi0VgmREQkGsuEiIhE+39JrYP29m3w4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using groupby, find out the number of reviews with\n",
    "# positive and negative sentiment respectively.\n",
    "df_target = df.groupby('bin').size().reset_index(name='n')\n",
    "print(df_target)\n",
    "\n",
    "# How many patients in the dataset have been diagnosed positive and negative for diabetes?\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "df_target.plot(kind='bar', x='bin', y='n', title = \"Target class count\", ax=ax1)\n",
    "ax1.set_ylabel(\"No. of Movies\")\n",
    "plt.xticks(np.arange(0,5), [\"<35k\", \"35k to 650k\", \"650k to 800k\", \"800k to 45mil\", \">45mil\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train-Test Split</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.651188Z",
     "start_time": "2018-11-02T13:49:14.642104Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = df.loc[:, df.columns != 'bin']\n",
    "X = df[['budget', 'weekday', 'day', 'month', 'year', 'runtime', 'weighted_rating']]\n",
    "#X = df[['log_budget', 'weekday', 'day', 'month', 'year', 'log_runtime', 'log_weighted_rating']]\n",
    "y = df[['bin']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baseline Classifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1       0       0       0     691       0\n",
      "true:2       0       0       0     718       0\n",
      "true:3       0       0       0     698       0\n",
      "true:4       0       0       0     667       0\n",
      "true:5       0       0       0     729       0\n",
      "Accuracy: 0.19040822152440764\n",
      "F1: 0.06398081534772182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = dummy.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. k-Nearest Neighbor (KNN)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [kNN Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- [DataCamp Implementation](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:59:24.193338Z",
     "start_time": "2018-11-02T13:59:24.179772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     342     172     112      53      12\n",
      "true:2     286     224     133      59      16\n",
      "true:3     192     191     173     107      35\n",
      "true:4     131     117     124     186     109\n",
      "true:5      62      69      70     159     369\n",
      "Accuracy: 0.3693976591493006\n",
      "F1: 0.3698591545261179\n",
      "Best Parameters: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "#Create the kNN classifier and set the number of neighbors. Note that you can tune this number of neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':list(range(1, 10)),\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "knn = GridSearchCV(knn, cv=3, param_grid=parameters, scoring='f1_macro')\n",
    "knn.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Bagging (with Decision Tree)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [Bagging Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "\n",
    "*Note that the default AdaBoost implementation in SKLearn is Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     428     165      73      23       2\n",
      "true:2     354     206     119      32       7\n",
      "true:3     202     179     192     109      16\n",
      "true:4     130     106      98     219     114\n",
      "true:5      78      72      40     109     430\n",
      "Accuracy: 0.42106765629460463\n",
      "F1: 0.41894830682831996\n",
      "Best Parameters: {'base_estimator__max_depth': 8, 'max_features': 0.7, 'max_samples': 0.5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "parameters = {\n",
    "    'base_estimator__max_depth' : list(range(1, 10)),\n",
    "    'n_estimators' : [100],\n",
    "    'max_features' : [0.5, 0.7],\n",
    "    'max_samples' : [0.05, 0.1, 0.2, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "baggingTree = GridSearchCV(\n",
    "                BaggingClassifier(DecisionTreeClassifier()), \n",
    "                cv=3,\n",
    "                param_grid=parameters, \n",
    "                scoring='f1_macro')\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "baggingTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = baggingTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",baggingTree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Bagging (with kNN)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     281     177     124      82      27\n",
      "true:2     223     212     151     102      30\n",
      "true:3     167     175     184     112      60\n",
      "true:4      85     110     128     199     145\n",
      "true:5      56      55      65     164     389\n",
      "Accuracy: 0.36111904082215246\n",
      "F1: 0.36069008171419303\n"
     ]
    }
   ],
   "source": [
    "#Create the kNN base classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "baggingknn = BaggingClassifier(n_estimators=50, base_estimator=knn)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "baggingknn.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = baggingknn.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. AdaBoost (with Decision Tree)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [AdaBoost Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "- [DataCamp Implementation](https://www.datacamp.com/community/tutorials/adaboost-classifier-python)\n",
    "- [Setting Learning Rate and N Estimators](https://stats.stackexchange.com/questions/82323/shrinkage-parameter-in-adaboost)\n",
    "\n",
    "*Note that the default AdaBoost implementation in SKLearn is Decision Tree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:56:38.864454Z",
     "start_time": "2018-11-02T13:56:38.853524Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     450     143      77      18       3\n",
      "true:2     379     169     135      29       6\n",
      "true:3     229     156     214      76      23\n",
      "true:4     155      92     132     192      96\n",
      "true:5      87      49      59     145     389\n",
      "Accuracy: 0.4036540108478447\n",
      "F1: 0.3994689959952912\n"
     ]
    }
   ],
   "source": [
    "#Create the AdaBoost classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "adaboostTree = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "adaboostTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = adaboostTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>5. AdaBoost (with Gaussian Navie Bayes)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [Gaussian Naive Bayes Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "- [Naive Bayes Classifier video](https://www.youtube.com/watch?v=CPqOCI0ahss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     639      28      14      10       0\n",
      "true:2     633      60      17       6       2\n",
      "true:3     503      93      51      46       5\n",
      "true:4     336      44      77     151      59\n",
      "true:5     182      24      41     188     294\n",
      "Accuracy: 0.3411361689980017\n",
      "F1: 0.2977363014353807\n"
     ]
    }
   ],
   "source": [
    "naivebayes = GaussianNB()\n",
    "#Fit the training feature Xs and training label Ys\n",
    "naivebayes.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = naivebayes.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1      59     604      12      15       1\n",
      "true:2      67     610      15      22       4\n",
      "true:3      67     514      35      73       9\n",
      "true:4      34     430      73     119      11\n",
      "true:5      15     318     111     182     103\n",
      "Accuracy: 0.26434484727376534\n",
      "F1: 0.20874901718791108\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "adaboostnaivebayes = AdaBoostClassifier(n_estimators=50,learning_rate=1, base_estimator=nb)\n",
    "#model = BaggingClassifier(n_estimators=50, base_estimator=knn)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "adaboostnaivebayes.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = adaboostnaivebayes.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>6. Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     498     106      66      17       4\n",
      "true:2     412     144     129      26       7\n",
      "true:3     275     115     206      84      18\n",
      "true:4     180      53     121     176     137\n",
      "true:5     108      43      43      94     441\n",
      "Accuracy: 0.41821296031972593\n",
      "F1: 0.4043495480364002\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "#Instantiate model\n",
    "randomforest = RandomForestClassifier()\n",
    "\n",
    "parameters = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "randomforest = GridSearchCV(randomforest, cv=3, param_grid=parameters, scoring='f1_macro')\n",
    "randomforest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = randomforest.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\", randomforest.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>7. Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     647       8      15      18       3\n",
      "true:2     646      17      30      20       5\n",
      "true:3     523      20      54      86      15\n",
      "true:4     336       9      38     150     134\n",
      "true:5     186       4      16     119     404\n",
      "Accuracy: 0.36311732800456753\n",
      "F1: 0.30146062117306716\n"
     ]
    }
   ],
   "source": [
    "#create a new logistic regression model ‘lbfgs’, ‘sag’ and ‘newton-cg’ solvers.\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "#fit the model to the training data\n",
    "log_reg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>8. Ensemble (Stacking with all models)</h1>\n",
    "\n",
    "As I mentioned in lecture, it is possible to ensemble different models. So how can we do that in python? Check out the following link and try it for your project!:\n",
    "https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     538      86      50      15       2\n",
      "true:2     483     120      87      22       6\n",
      "true:3     311     118     173      85      11\n",
      "true:4     207      59     100     203      98\n",
      "true:5     121      42      39     126     401\n",
      "Accuracy: 0.4096488723950899\n",
      "F1: 0.3951199712853787\n"
     ]
    }
   ],
   "source": [
    "#knn with best parameters\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=3, n_jobs=-1, n_neighbors=9)\n",
    "knn.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#baggingTree with best parameters\n",
    "baggingTree = BaggingClassifier(DecisionTreeClassifier(max_depth=8), max_features=0.7, max_samples=0.5, n_estimators=100)\n",
    "baggingTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#random forest with best parameters\n",
    "randomforest = RandomForestClassifier(criterion='gini', max_depth=6, max_features='log2', n_estimators=500)\n",
    "randomforest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#create a dictionary of our models\n",
    "estimators=[('knn', knn), \n",
    "            ('baggingTree', baggingTree),\n",
    "            ('baggingknn', baggingknn),\n",
    "            ('adaboostTree', adaboostTree),\n",
    "            #('naivebayes', naivebayes),\n",
    "            #('adaboostnaivebayes', adaboostnaivebayes),\n",
    "            ('randomforest', randomforest), \n",
    "            ('log_reg', log_reg)]\n",
    "\n",
    "#create our voting classifier, inputting our models, voting hard means asking classifers to make predictions by majority vote\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
