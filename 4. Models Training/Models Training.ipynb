{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import all libraries and reading explored data into Dataframe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.197888Z",
     "start_time": "2018-11-02T13:49:12.900261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget                 float64\n",
      "revenue                float64\n",
      "weekday                float64\n",
      "day                    float64\n",
      "month                  float64\n",
      "year                   float64\n",
      "runtime                float64\n",
      "vote_average           float64\n",
      "vote_count             float64\n",
      "weighted_rating        float64\n",
      "bin                    float64\n",
      "log_revenue            float64\n",
      "log_budget             float64\n",
      "log_runtime            float64\n",
      "log_vote_count         float64\n",
      "log_vote_average       float64\n",
      "log_weighted_rating    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>weighted_rating</th>\n",
       "      <th>bin</th>\n",
       "      <th>log_revenue</th>\n",
       "      <th>log_budget</th>\n",
       "      <th>log_runtime</th>\n",
       "      <th>log_vote_count</th>\n",
       "      <th>log_vote_average</th>\n",
       "      <th>log_weighted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12725</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2281569.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1990.00</td>\n",
       "      <td>92.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>14.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2300.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9577</th>\n",
       "      <td>2000000.00</td>\n",
       "      <td>661946.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2012.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>13.40</td>\n",
       "      <td>14.51</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1144438.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>13.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>0.00</td>\n",
       "      <td>100600.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>11.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          budget    revenue  weekday   day  month    year  runtime  \\\n",
       "12725       0.00 2281569.00     4.00 15.00   2.00 1990.00    92.00   \n",
       "9122        0.00    2300.00     5.00  8.00   4.00 2016.00    70.00   \n",
       "9577  2000000.00  661946.00     7.00  1.00   1.00 2012.00    30.00   \n",
       "1802        0.00 1144438.00     2.00 10.00   4.00 2007.00    14.00   \n",
       "9647        0.00  100600.00     5.00 30.00   1.00 2015.00    85.00   \n",
       "\n",
       "       vote_average  vote_count  weighted_rating  bin  log_revenue  \\\n",
       "12725          6.70       10.00             7.00 3.00        14.64   \n",
       "9122           5.00       13.00             7.00 1.00         7.74   \n",
       "9577          10.00        1.00             7.00 3.00        13.40   \n",
       "1802           0.00        0.00             7.00 3.00        13.95   \n",
       "9647           0.00        2.00             7.00 2.00        11.52   \n",
       "\n",
       "       log_budget  log_runtime  log_vote_count  log_vote_average  \\\n",
       "12725        0.00         4.52            2.30              1.90   \n",
       "9122         0.00         4.25            2.56              1.61   \n",
       "9577        14.51         3.40            0.00              2.30   \n",
       "1802         0.00         2.64            0.00              0.00   \n",
       "9647         0.00         4.44            0.69              0.00   \n",
       "\n",
       "       log_weighted_rating  \n",
       "12725                 1.95  \n",
       "9122                  1.95  \n",
       "9577                  1.95  \n",
       "1802                  1.95  \n",
       "9647                  1.95  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import io\n",
    "\n",
    "#General libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Libraries for data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Libraries for data pre-processing (Log Loss)\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#For Decision Tree implementation\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#For KNN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#For AdaBoost implementation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#For Random Forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#For Baseline implementation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#For Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#For Ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#Settings\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "sns.set()\n",
    "\n",
    "def printModelAccuracy(y_test, y_pred):\n",
    "    # Find the confusion matrix of the result\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=[1, 2, 3, 4, 5]), \\\n",
    "        index=['true:1', 'true:2', 'true:3', 'true:4', 'true:5'], \n",
    "        columns=['pred:1', 'pred:2', 'pred:3', 'pred:4', 'pred:5'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Find the accuracy and F1 score of the result\n",
    "    asr = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Accuracy:\", asr)\n",
    "    print(\"F1:\", f1)\n",
    "    \"\"\"\n",
    "    # Log loss\n",
    "    score = log_loss(y_test, y_pred)\n",
    "    print(\"Log Loss:\", score)\n",
    "    \"\"\"\n",
    "    \n",
    "# Read from dataframe\n",
    "df = pd.read_pickle(\"explored_data\")\n",
    "df = df.replace([np.inf, -np.inf, np.nan], 0) #removing infinite/nan values\n",
    "\n",
    "# Check the columns using dtypes\n",
    "print(df.dtypes)\n",
    "# Randomly sample 5 records with .sample(5)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor column in df.columns:\\n    if df[column].dtype == type(object):\\n        #Create the label encoder\\n        le = preprocessing.LabelEncoder()\\n        #Convert the non numeric data to numeric\\n        df[column] = le.fit_transform(df[column])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree in SKLearn don't take in string well. So we use a label encoder to change that string to a numeric value\n",
    "\"\"\"\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == type(object):\n",
    "        #Create the label encoder\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        #Convert the non numeric data to numeric\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Find out the number of records per revenue bin. </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:55:55.489674Z",
     "start_time": "2018-11-02T13:55:55.227099Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bin     n\n",
      "0 1.00  3502\n",
      "1 2.00  3500\n",
      "2 3.00  3502\n",
      "3 4.00  3502\n",
      "4 5.00  3505\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using groupby, find out the number of reviews with\n",
    "# positive and negative sentiment respectively.\n",
    "df_target = df.groupby('bin').size().reset_index(name='n')\n",
    "print(df_target)\n",
    "\n",
    "# How many patients in the dataset have been diagnosed positive and negative for diabetes?\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "df_target.plot(kind='bar', x='bin', y='n', title = \"Target class count\", ax=ax1)\n",
    "ax1.set_ylabel(\"No. of Movies\")\n",
    "plt.xticks(np.arange(0,5), [\"<35k\", \"35k to 650k\", \"650k to 800k\", \"800k to 45mil\", \">45mil\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train-Test Split</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.651188Z",
     "start_time": "2018-11-02T13:49:14.642104Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = df.loc[:, df.columns != 'bin']\n",
    "X = df[['budget', 'weekday', 'day', 'month', 'year', 'runtime', 'weighted_rating']]\n",
    "#X = df[['log_budget', 'weekday', 'day', 'month', 'year', 'log_runtime', 'log_weighted_rating']]\n",
    "y = df[['bin']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baseline Classifier (Decision Tree)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     402     206      67      11       5\n",
      "true:2     329     284      77      22       6\n",
      "true:3     183     287     118      88      22\n",
      "true:4     117     164      81     199     106\n",
      "true:5      69     105      24     150     381\n",
      "Accuracy: 0.39508992292320866\n",
      "F1: 0.3905269955189576\n",
      "Best Parameters: {'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'max_depth' : list(range(5, 10))\n",
    "}\n",
    "\n",
    "decisionTree = GridSearchCV(DecisionTreeClassifier(), cv=3, param_grid=parameters)\n",
    "#Fit the training feature Xs and training label Ys\n",
    "decisionTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = decisionTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",decisionTree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. k-Nearest Neighbor (KNN)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [kNN Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- [DataCamp Implementation](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:59:24.193338Z",
     "start_time": "2018-11-02T13:59:24.179772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     342     172     112      53      12\n",
      "true:2     286     224     133      59      16\n",
      "true:3     192     191     173     107      35\n",
      "true:4     131     117     124     186     109\n",
      "true:5      62      69      70     159     369\n",
      "Accuracy: 0.3693976591493006\n",
      "F1: 0.3698591545261179\n",
      "Best Parameters: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "#Create the kNN classifier and set the number of neighbors. Note that you can tune this number of neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':list(range(1, 10)),\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "knn = GridSearchCV(\n",
    "        knn, \n",
    "        cv=3, \n",
    "        param_grid=parameters, \n",
    "        scoring='f1_macro')\n",
    "\n",
    "knn.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Bagging (with Decision Tree)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [Bagging Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "\n",
    "*Note that the default AdaBoost implementation in SKLearn is Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\andy_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     439     154      66      29       3\n",
      "true:2     341     206     130      33       8\n",
      "true:3     197     174     198     111      18\n",
      "true:4     136      97     101     226     107\n",
      "true:5      81      67      40     120     421\n",
      "Accuracy: 0.42534970025692265\n",
      "F1: 0.4227534407476826\n",
      "Best Parameters: {'base_estimator__max_depth': 8, 'max_features': 0.6, 'max_samples': 0.7, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "parameters = {\n",
    "    'base_estimator__max_depth' : list(range(5, 10)),\n",
    "    'n_estimators' : [100, 200],\n",
    "    'max_features' : [0.5, 0.6, 0.7],\n",
    "    'max_samples' : [0.6, 0.7]\n",
    "}\n",
    "\n",
    "baggingTree = GridSearchCV(\n",
    "                BaggingClassifier(DecisionTreeClassifier()), \n",
    "                cv=3,\n",
    "                param_grid=parameters, \n",
    "                scoring='f1_macro')\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "baggingTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = baggingTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",baggingTree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Bagging (with kNN)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     370     189      91      33       8\n",
      "true:2     305     226     122      53      12\n",
      "true:3     176     193     193     113      23\n",
      "true:4     121     109     129     192     116\n",
      "true:5      75      60      63     135     396\n",
      "Accuracy: 0.3930916357407936\n",
      "F1: 0.39293148950811585\n",
      "Best Parameters: {'max_features': 0.5, 'max_samples': 0.7, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "#Create the kNN base classifier\n",
    "parameters = {\n",
    "    'n_estimators' : [100, 200],\n",
    "    'max_features' : [0.5, 0.6, 0.7],\n",
    "    'max_samples' : [0.6, 0.7]\n",
    "}\n",
    "\n",
    "baggingknn = GridSearchCV(\n",
    "                BaggingClassifier(KNeighborsClassifier(algorithm='auto', leaf_size=3, n_jobs=-1, n_neighbors=9)), \n",
    "                cv=3,\n",
    "                param_grid=parameters, \n",
    "                scoring='f1_macro')\n",
    "\n",
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "#baggingknn = BaggingClassifier(n_estimators=50, base_estimator=knn)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "baggingknn.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = baggingknn.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",baggingknn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. AdaBoost (with Decision Tree)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [AdaBoost Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "- [DataCamp Implementation](https://www.datacamp.com/community/tutorials/adaboost-classifier-python)\n",
    "- [Setting Learning Rate and N Estimators](https://stats.stackexchange.com/questions/82323/shrinkage-parameter-in-adaboost)\n",
    "\n",
    "*Note that the default AdaBoost implementation in SKLearn is Decision Tree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:56:38.864454Z",
     "start_time": "2018-11-02T13:56:38.853524Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     402     206      67      11       5\n",
      "true:2     329     284      77      22       6\n",
      "true:3     183     287     119      87      22\n",
      "true:4     117     164      82     199     105\n",
      "true:5      69     105      23     152     380\n",
      "Accuracy: 0.39508992292320866\n",
      "F1: 0.3906740636178915\n",
      "Best Parameters: {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 8, 'base_estimator__splitter': 'best', 'learning_rate': 2, 'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "#Create the AdaBoost classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "parameters = {\"base_estimator__max_depth\" : list(range(5, 10)),\n",
    "              \"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"n_estimators\": [1, 50, 100, 200],\n",
    "              \"learning_rate\": [1, 2]\n",
    "             }\n",
    "\n",
    "adaboostTree = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier()), cv=3, param_grid=parameters)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "adaboostTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = adaboostTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "print(\"Best Parameters:\",adaboostTree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>5. AdaBoost (with Gaussian Navie Bayes)</h1>\n",
    "\n",
    "Refer to the following links on for detail explanation on the implementation:\n",
    "- [Gaussian Naive Bayes Classifier SKLearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "- [Naive Bayes Classifier video](https://www.youtube.com/watch?v=CPqOCI0ahss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     639      28      14      10       0\n",
      "true:2     633      60      17       6       2\n",
      "true:3     503      93      51      46       5\n",
      "true:4     336      44      77     151      59\n",
      "true:5     182      24      41     188     294\n",
      "Accuracy: 0.3411361689980017\n",
      "F1: 0.2977363014353807\n"
     ]
    }
   ],
   "source": [
    "naivebayes = GaussianNB()\n",
    "#Fit the training feature Xs and training label Ys\n",
    "naivebayes.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = naivebayes.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1      59     604      12      15       1\n",
      "true:2      67     610      15      22       4\n",
      "true:3      67     514      35      73       9\n",
      "true:4      34     430      73     119      11\n",
      "true:5      15     318     111     182     103\n",
      "Accuracy: 0.26434484727376534\n",
      "F1: 0.20874901718791108\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "adaboostnaivebayes = AdaBoostClassifier(n_estimators=50,learning_rate=1, base_estimator=nb)\n",
    "#model = BaggingClassifier(n_estimators=50, base_estimator=knn)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "adaboostnaivebayes.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = adaboostnaivebayes.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>6. Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     498     106      66      17       4\n",
      "true:2     412     144     129      26       7\n",
      "true:3     275     115     206      84      18\n",
      "true:4     180      53     121     176     137\n",
      "true:5     108      43      43      94     441\n",
      "Accuracy: 0.41821296031972593\n",
      "F1: 0.4043495480364002\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "#Instantiate model\n",
    "randomforest = RandomForestClassifier()\n",
    "\n",
    "parameters = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "randomforest = GridSearchCV(randomforest, cv=3, param_grid=parameters, scoring='f1_macro')\n",
    "randomforest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = randomforest.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\", randomforest.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>7. Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     647       8      15      18       3\n",
      "true:2     646      17      30      20       5\n",
      "true:3     523      20      54      86      15\n",
      "true:4     336       9      38     150     134\n",
      "true:5     186       4      16     119     404\n",
      "Accuracy: 0.36311732800456753\n",
      "F1: 0.30146062117306716\n"
     ]
    }
   ],
   "source": [
    "#create a new logistic regression model lbfgs, sag and newton-cg solvers.\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "#fit the model to the training data\n",
    "log_reg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>8. Ensemble (Stacking with all models)</h1>\n",
    "\n",
    "As I mentioned in lecture, it is possible to ensemble different models. So how can we do that in python? Check out the following link and try it for your project!:\n",
    "https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     538      86      50      15       2\n",
      "true:2     483     120      87      22       6\n",
      "true:3     311     118     173      85      11\n",
      "true:4     207      59     100     203      98\n",
      "true:5     121      42      39     126     401\n",
      "Accuracy: 0.4096488723950899\n",
      "F1: 0.3951199712853787\n"
     ]
    }
   ],
   "source": [
    "#knn with best parameters\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=3, n_jobs=-1, n_neighbors=9)\n",
    "knn.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#baggingTree with best parameters\n",
    "baggingTree = BaggingClassifier(DecisionTreeClassifier(max_depth=8), max_features=0.7, max_samples=0.5, n_estimators=100)\n",
    "baggingTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#baggingknn with best parameters\n",
    "baggingknn = BaggingClassifier(knn, max_features=0.5, max_samples=0.7, n_estimators=200)\n",
    "baggingknn.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Adaboost(DecisionTree) with best parameters\n",
    "adaboostTree = AdaBoostClassifier(DecisionTreeClassifier(criterion='gini', max_depth=8, splitter='best'), learning_rate=2, n_estimators=1)\n",
    "adaboostTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#random forest with best parameters\n",
    "randomforest = RandomForestClassifier(criterion='gini', max_depth=6, max_features='log2', n_estimators=500)\n",
    "randomforest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#create a dictionary of our models\n",
    "estimators=[('knn', knn), \n",
    "            ('baggingTree', baggingTree),\n",
    "            ('baggingknn', baggingknn),\n",
    "            ('adaboostTree', adaboostTree),\n",
    "            #('naivebayes', naivebayes),\n",
    "            #('adaboostnaivebayes', adaboostnaivebayes),\n",
    "            ('randomforest', randomforest), \n",
    "            ('log_reg', log_reg)]\n",
    "\n",
    "#create our voting classifier, inputting our models, voting hard means asking classifers to make predictions by majority vote\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
