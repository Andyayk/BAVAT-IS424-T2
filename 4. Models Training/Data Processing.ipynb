{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import all libraries and reading explored data into Dataframe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.197888Z",
     "start_time": "2018-11-02T13:49:12.900261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget        float64\n",
      "vote_count    float64\n",
      "bin           float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14666</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       budget  vote_count  bin\n",
       "3254    -0.40       -0.27 3.00\n",
       "1855    -0.40       -0.27 3.00\n",
       "3748    -0.39       -0.27 2.00\n",
       "14666   -0.40       -0.26 2.00\n",
       "4434    -0.37       -0.27 2.00"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import io\n",
    "\n",
    "#General libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Libraries for data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Libraries for data pre-processing (Log Loss)\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#For Decision Tree implementation\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#For KNN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#For AdaBoost implementation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#For Random Forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#For Baseline implementation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#For Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#For Ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#Settings\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "sns.set()\n",
    "\n",
    "def printModelAccuracy(y_test, y_pred):\n",
    "    # Find the confusion matrix of the result\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=[1, 2, 3, 4, 5]), \\\n",
    "        index=['true:1', 'true:2', 'true:3', 'true:4', 'true:5'], \n",
    "        columns=['pred:1', 'pred:2', 'pred:3', 'pred:4', 'pred:5'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Find the accuracy and F1 score of the result\n",
    "    asr = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Accuracy:\", asr)\n",
    "    print(\"F1:\", f1)\n",
    "    \"\"\"\n",
    "    # Log loss\n",
    "    score = log_loss(y_test, y_pred)\n",
    "    print(\"Log Loss:\", score)\n",
    "    \"\"\"\n",
    "    \n",
    "# Read from dataframe\n",
    "dfnum = pd.read_pickle(\"../3. Exploratory Data Analysis/explored_data\")\n",
    "dfnum = dfnum.replace([np.inf, -np.inf, np.nan], 0) #removing infinite/nan values\n",
    "df = dfnum.drop(['id'], 1) # use only num data\n",
    "\n",
    "# Check the columns using dtypes\n",
    "print(df.dtypes)\n",
    "# Randomly sample 5 records with .sample(5)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Files for Experiment E\n",
    "Numerical data + only genres and production companies (without PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfnum\n",
      "(19560, 4)\n",
      "dfgenres\n",
      "(23579, 20)\n",
      "dfproductioncompanies_s\n",
      "(23579, 1001)\n",
      "final_df without dfnum\n",
      "(23579, 1020)\n",
      "final_df with dfnum\n",
      "(19560, 1023)\n",
      "budget                      float64\n",
      "vote_count                  float64\n",
      "id                          float64\n",
      "bin                         float64\n",
      "action                      float64\n",
      "adventure                   float64\n",
      "animation                   float64\n",
      "comedy                      float64\n",
      "crime                       float64\n",
      "documentary                 float64\n",
      "drama                       float64\n",
      "family                      float64\n",
      "fantasy                     float64\n",
      "history                     float64\n",
      "horror                      float64\n",
      "music                       float64\n",
      "mystery                     float64\n",
      "romance                     float64\n",
      "sciencefiction              float64\n",
      "thriller                    float64\n",
      "tvmovie                     float64\n",
      "war                         float64\n",
      "western                     float64\n",
      "aamirkhanproductions        float64\n",
      "aardmananimations           float64\n",
      "aashirvadcinemas            float64\n",
      "abandapart                  float64\n",
      "abccirclefilms              float64\n",
      "abcpictures                 float64\n",
      "abundantiaentertainment     float64\n",
      "                             ...   \n",
      "wgbhboston                  float64\n",
      "whitewaterfilms             float64\n",
      "whynotproductions           float64\n",
      "wickedpictures              float64\n",
      "wildbunch                   float64\n",
      "wildgazefilms               float64\n",
      "wildwoodenterprises         float64\n",
      "williamcastleproductions    float64\n",
      "willpackerproductions       float64\n",
      "winddancerproductions       float64\n",
      "wingnutfilms                float64\n",
      "winklerfilms                float64\n",
      "wonderlandsoundandvision    float64\n",
      "workingtitlefilms           float64\n",
      "worldviewentertainment      float64\n",
      "wwestudios                  float64\n",
      "xyzfilms                    float64\n",
      "yarifilmgroup               float64\n",
      "yashrajfilms                float64\n",
      "yle                         float64\n",
      "yongfilm                    float64\n",
      "yorkshiretelevision         float64\n",
      "zagrebfilm                  float64\n",
      "zanearts                    float64\n",
      "zdf                         float64\n",
      "zenithentertainment         float64\n",
      "zentropaentertainments      float64\n",
      "zephyrfilms                 float64\n",
      "zerogravitymanagement       float64\n",
      "zipcinema                   float64\n",
      "Length: 1023, dtype: object\n",
      "       budget  vote_count        id  bin  action  adventure  animation  \\\n",
      "3067    -0.40       -0.24 379441.00 3.00    0.00       0.00       0.00   \n",
      "13630   -0.34       -0.22  15977.00 3.00    0.00       0.00       0.00   \n",
      "12751   -0.40       -0.25  12823.00 3.00    0.00       0.00       0.00   \n",
      "16419   -0.40       -0.20  63686.00 3.00    0.48       0.58       0.66   \n",
      "13359   -0.33       -0.25  14806.00 3.00    0.00       0.00       0.00   \n",
      "\n",
      "       comedy  crime  documentary    ...      yongfilm  yorkshiretelevision  \\\n",
      "3067     0.00   0.00         0.00    ...          0.00                 0.00   \n",
      "13630    0.57   0.00         0.00    ...          0.00                 0.00   \n",
      "12751    0.00   0.00         0.00    ...          0.00                 0.00   \n",
      "16419    0.00   0.00         0.00    ...          0.00                 0.00   \n",
      "13359    0.00   0.00         0.00    ...          0.00                 0.00   \n",
      "\n",
      "       zagrebfilm  zanearts  zdf  zenithentertainment  zentropaentertainments  \\\n",
      "3067         0.00      0.00 0.00                 0.00                    0.00   \n",
      "13630        0.00      0.00 0.00                 0.00                    0.00   \n",
      "12751        0.00      0.00 0.00                 0.00                    0.00   \n",
      "16419        0.00      0.00 0.00                 0.00                    0.00   \n",
      "13359        0.00      0.00 0.00                 0.00                    0.00   \n",
      "\n",
      "       zephyrfilms  zerogravitymanagement  zipcinema  \n",
      "3067          0.00                   0.00       0.00  \n",
      "13630         0.00                   0.00       0.00  \n",
      "12751         0.00                   0.00       0.00  \n",
      "16419         0.00                   0.00       0.00  \n",
      "13359         0.00                   0.00       0.00  \n",
      "\n",
      "[5 rows x 1023 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine datasets into one df (without PCA)\n",
    "\n",
    "# Read from text dataframes (before PCA)\n",
    "print(\"dfnum\")\n",
    "print(dfnum.shape)\n",
    "\n",
    "dfgenres = pd.read_pickle(\"../2. Data Preprocessing/dfgenres\")\n",
    "dfgenres.columns = [x[0] for x in dfgenres.columns]\n",
    "dfgenres = dfgenres.sort_values('id')\n",
    "dfgenres.drop(['title'], 1, inplace=True) # keep id here as genres has no missing values\n",
    "# print(dfgenres.sample(5))\n",
    "print(\"dfgenres\")\n",
    "print(dfgenres.shape)\n",
    "\n",
    "dfproductioncompanies_s = pd.read_pickle(\"../2. Data Preprocessing/dfproductioncompaniesmostcommon\")\n",
    "dfproductioncompanies_s.columns = [x[0] for x in dfproductioncompanies_s.columns]\n",
    "dfproductioncompanies_s = dfproductioncompanies_s.sort_values('id')\n",
    "dfproductioncompanies_s.drop(['title'], 1, inplace=True)\n",
    "# print(dfproductioncompanies_s.sample(5))\n",
    "print(\"dfproductioncompanies_s\")\n",
    "print(dfproductioncompanies_s.shape)\n",
    "\n",
    "# Combine dataframes\n",
    "final_df = pd.merge(dfgenres, dfproductioncompanies_s, on='id', how='left')\n",
    "final_df[\"id\"] = pd.to_numeric(final_df[\"id\"])\n",
    "final_df = final_df.replace([np.inf, -np.inf, np.nan], 0) #removing infinite/nan values\n",
    "print(\"final_df without dfnum\")\n",
    "print(final_df.shape)\n",
    "\n",
    "final_df = pd.merge(dfnum, final_df, on='id', how='left')\n",
    "final_df = final_df.replace([np.inf, -np.inf, np.nan], 0) #removing infinite/nan values\n",
    "print(\"final_df with dfnum\")\n",
    "print(final_df.shape)\n",
    "\n",
    "final_df.to_pickle(\"withoutpca_imptdata\")\n",
    "\n",
    "# Check the columns using dtypes\n",
    "print(final_df.dtypes)\n",
    "\n",
    "# Randomly sample 5 records with .sample(5)\n",
    "print(final_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Process Files for Experiment B & C</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets into one df (without PCA)\n",
    "\n",
    "# Read from text dataframes (before PCA)\n",
    "print(\"dfnum\")\n",
    "print(dfnum.shape)\n",
    "\n",
    "dfcasts = pd.read_pickle(\"../2. Data Preprocessing/dfcasts\")\n",
    "dfcasts.columns = [x[0] for x in dfcasts.columns]\n",
    "dfcasts = dfcasts.sort_values('id')\n",
    "# dfcasts.drop(['id'], 1, inplace=True)\n",
    "# print(dfcasts.sample(5))\n",
    "print(\"dfcasts\")\n",
    "print(dfcasts.shape)\n",
    "\n",
    "dfdirectors = pd.read_pickle(\"../2. Data Preprocessing/dfdirectors\")\n",
    "dfdirectors.columns = [x[0] for x in dfdirectors.columns]\n",
    "dfdirectors = dfdirectors.sort_values('id')\n",
    "# dfdirectors.drop(['id'], 1, inplace=True)\n",
    "# print(dfdirectors.sample(5))\n",
    "print(\"dfdirectors\")\n",
    "print(dfdirectors.shape)\n",
    "\n",
    "dfgenres = pd.read_pickle(\"../2. Data Preprocessing/dfgenres\")\n",
    "dfgenres.columns = [x[0] for x in dfgenres.columns]\n",
    "dfgenres = dfgenres.sort_values('id')\n",
    "dfgenres.drop(['title'], 1, inplace=True) # keep id here as genres has no missing values\n",
    "# print(dfgenres.sample(5))\n",
    "print(\"dfgenres\")\n",
    "print(dfgenres.shape)\n",
    "\n",
    "dfoverview_s = pd.read_pickle(\"../2. Data Preprocessing/dfoverviewmostcommon\")\n",
    "dfoverview_s.columns = [x[0] for x in dfoverview_s.columns]\n",
    "dfoverview_s = dfoverview_s.sort_values('id')\n",
    "dfoverview_s.drop(['title'], 1, inplace=True)\n",
    "# print(dfoverview_s.sample(5))\n",
    "print(\"dfoverview_s\")\n",
    "print(dfoverview_s.shape)\n",
    "\n",
    "dfproductioncompanies_s = pd.read_pickle(\"../2. Data Preprocessing/dfproductioncompaniesmostcommon\")\n",
    "dfproductioncompanies_s.columns = [x[0] for x in dfproductioncompanies_s.columns]\n",
    "dfproductioncompanies_s = dfproductioncompanies_s.sort_values('id')\n",
    "dfproductioncompanies_s.drop(['title'], 1, inplace=True)\n",
    "# print(dfproductioncompanies_s.sample(5))\n",
    "print(\"dfproductioncompanies_s\")\n",
    "print(dfproductioncompanies_s.shape)\n",
    "\n",
    "# COMMENTED OUT overview & production companies because of MEMORY ERROR\n",
    "\"\"\"\n",
    "dfoverview = pd.read_pickle(\"../2. Data Preprocessing/dfoverview\")\n",
    "dfoverview.columns = [x[0] for x in dfoverview.columns]\n",
    "dfoverview = dfoverview.sort_values('id')\n",
    "dfoverview.drop(['title'], 1, inplace=True)\n",
    "# print(dfoverview.sample(5))\n",
    "print(\"dfoverview\")\n",
    "print(dfoverview.shape)\n",
    "\n",
    "dfproductioncompanies = pd.read_pickle(\"../2. Data Preprocessing/dfproductioncompanies\")\n",
    "dfproductioncompanies.columns = [x[0] for x in dfproductioncompanies.columns]\n",
    "dfproductioncompanies = dfproductioncompanies.sort_values('id')\n",
    "dfproductioncompanies.drop(['title'], 1, inplace=True)\n",
    "# print(dfproductioncompanies.sample(5))\n",
    "print(\"dfproductioncompanies\")\n",
    "print(dfproductioncompanies.shape)\n",
    "\"\"\"\n",
    "\n",
    "# Combine dataframes\n",
    "casts_directors = pd.merge(dfcasts, dfdirectors, on='id', how='left')\n",
    "cd_genres = pd.merge(casts_directors, dfgenres, on='id', how='right')\n",
    "overview_productioncompanies = pd.merge(dfoverview_s, dfproductioncompanies_s, on='id', how='left')\n",
    "final_df = pd.merge(cd_genres, overview_productioncompanies, on='id', how='right')\n",
    "\n",
    "final_df[\"id\"] = pd.to_numeric(final_df[\"id\"])\n",
    "final_df = final_df.replace([np.inf, -np.inf, np.nan], 0) #removing infinite/nan values\n",
    "print(\"final_df without dfnum\")\n",
    "print(final_df.shape)\n",
    "\n",
    "final_df = pd.merge(dfnum, final_df, on='id', how='left')\n",
    "final_df = final_df.replace([np.inf, -np.inf, np.nan], 0) #removing infinite/nan values\n",
    "print(\"final_df with dfnum\")\n",
    "print(final_df.shape)\n",
    "\n",
    "final_df.to_pickle(\"withoutpca_data\")\n",
    "\n",
    "final_df = final_df.drop(['budget_x', 'vote_count'], 1)\n",
    "final_df.to_pickle(\"withoutpca_textdata\")\n",
    "\n",
    "# Check the columns using dtypes\n",
    "print(final_df.dtypes)\n",
    "\n",
    "# Randomly sample 5 records with .sample(5)\n",
    "print(final_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read Experiment A</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical & numerical attributes only\n",
    "df = pd.read_pickle(\"../3. Exploratory Data Analysis/explored_data\")\n",
    "df = df.drop(['id'], 1)\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read Experiment B</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use textual attributes only\n",
    "df = pd.read_pickle(\"withoutpca_textdata\")\n",
    "df = df.drop(['id'], 1)\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read Experiment C</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use concatenation of (1) categorical & numerical attributes, and (2) TF-IDF vectors\n",
    "df = pd.read_pickle(\"withoutpca_data\")\n",
    "df = df.drop(['id'], 1)\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read Experiment D</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use concatenation of (1) categorical & numerical attributes, \n",
    "# and (2) lower dimension vector after performing dimension reduction on original TF-IDF vector\n",
    "df = pd.read_pickle(\"../3. Exploratory Data Analysis/pca_data\")\n",
    "df = df.drop(['id'], 1)\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Find out the number of records per revenue bin. </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:55:55.489674Z",
     "start_time": "2018-11-02T13:55:55.227099Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using groupby, find out the number of reviews with\n",
    "# positive and negative sentiment respectively.\n",
    "#df_target = df.groupby('bin').size().reset_index(name='n')\n",
    "#print(df_target)\n",
    "\n",
    "# How many patients in the dataset have been diagnosed positive and negative for diabetes?\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax1 = fig.add_subplot(111)\n",
    "#df_target.plot(kind='bar', x='bin', y='n', title = \"Target class count\", ax=ax1)\n",
    "#ax1.set_ylabel(\"No. of Movies\")\n",
    "#plt.xticks(np.arange(0,5), [\"<35k\", \"35k to 650k\", \"650k to 800k\", \"800k to 45mil\", \">45mil\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train-Test Split</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:49:14.651188Z",
     "start_time": "2018-11-02T13:49:14.642104Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'bin']\n",
    "y = df[['bin']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"X_train\")\n",
    "X_test.to_pickle(\"X_test\")\n",
    "y_train.to_pickle(\"y_train\")\n",
    "y_test.to_pickle(\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from dataframe    \n",
    "X_test = pd.read_pickle(\"X_test\")\n",
    "X_train = pd.read_pickle(\"X_train\")\n",
    "y_test = pd.read_pickle(\"y_test\")\n",
    "y_train = pd.read_pickle(\"y_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baseline Classifier (Decision Tree)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:1  pred:2  pred:3  pred:4  pred:5\n",
      "true:1     250     206     169     102      62\n",
      "true:2     249     199     172     110      72\n",
      "true:3     140     191     209     147      99\n",
      "true:4     102     100     187     220     190\n",
      "true:5      52      60      81     173     370\n",
      "Accuracy: 0.31901840490797545\n",
      "F1: 0.31901840490797545\n",
      "Best Parameters: {'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy'] #entropy better than gini\n",
    "}\n",
    "\n",
    "decisionTree = GridSearchCV(DecisionTreeClassifier(), cv=5, param_grid=parameters)\n",
    "#Fit the training feature Xs and training label Ys\n",
    "decisionTree.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = decisionTree.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix, the accuracy, and F1 score of the result\n",
    "printModelAccuracy(y_test, y_pred)\n",
    "\n",
    "# Best hyperparameters to use for model\n",
    "print(\"Best Parameters:\",decisionTree.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
