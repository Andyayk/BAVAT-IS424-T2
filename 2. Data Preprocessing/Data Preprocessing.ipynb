{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Separating JSON Data into Columns (Movies)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are budget, genres, homepage, id, original_language, original_title, overview, popularity, production_companies, production_countries, release_date, revenue, runtime, spoken_languages, status, tagline, title, vote_average, vote_count\n",
      "Processed 6 lines.\n",
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import csv, json, gensim, datetime, time\n",
    "from gensim import corpora\n",
    "\n",
    "rowslist = []\n",
    "genreslist = []\n",
    "#productioncompanieslist = []\n",
    "#productioncountrieslist = []\n",
    "\n",
    "def readJSON(row, rownumber, list, keyword):\n",
    "    jsonstring = row[rownumber]\n",
    "\n",
    "    jsonobj = json.loads(jsonstring)\n",
    "\n",
    "    for jsonelement in jsonobj:\n",
    "        keywordelement = jsonelement[keyword]       \n",
    "        list.append(keywordelement.lower()) \n",
    "    \n",
    "    return list\n",
    "    \n",
    "#read file\n",
    "with open('tmdb_10000_movies.csv', encoding='utf-8') as csv_file: #change accordingly\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        try:        \n",
    "            if line_count == 0:\n",
    "                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else: #if line_count != 5:\n",
    "                eachnewrow = []\n",
    "                genres = []\n",
    "                productioncompanies = []\n",
    "                productioncountries = []\n",
    "\n",
    "                eachnewrow.append(row[0]) #budget\n",
    "\n",
    "                #handle json genres\n",
    "                genres = readJSON(row, 1, genres, 'name')\n",
    "\n",
    "                eachnewrow.append(genres) #genres\n",
    "                genreslist.append(genres)\n",
    "\n",
    "                #row[2] homepage removed\n",
    "                eachnewrow.append(row[3]) #id\n",
    "\n",
    "                #row[4] original_language removed\n",
    "                #row[5] original_title removed  \n",
    "                #row[6] overview removed                    \n",
    "                eachnewrow.append(row[7]) #popularity                  \n",
    "\n",
    "                #handle json productioncompanies\n",
    "                productioncompanies = readJSON(row, 8, productioncompanies, 'name')\n",
    "\n",
    "                eachnewrow.append(len(productioncompanies)) #productioncompanies\n",
    "                #productioncompanieslist.append(productioncompanies)                  \n",
    "\n",
    "                #handle json productioncountries\n",
    "                productioncountries = readJSON(row, 9, productioncountries, 'name')\n",
    "\n",
    "                eachnewrow.append(len(productioncountries)) #productioncountries\n",
    "                #productioncountrieslist.append(productioncountries) \n",
    "\n",
    "                weekday = \"\"\n",
    "                day = \"\"\n",
    "                month = \"\"\n",
    "                year = \"\"                 \n",
    "\n",
    "                #handle releasedate \n",
    "                if row[10] != \"\":\n",
    "                    d = datetime.datetime.strptime(row[10] ,'%Y-%m-%d')\n",
    "\n",
    "                    weekdayword = d.strftime('%a')\n",
    "                    weekday = time.strptime(weekdayword, '%a').tm_wday + 1\n",
    "\n",
    "                    day = d.strftime('%d')\n",
    "\n",
    "                    monthword = d.strftime('%b')\n",
    "                    month = time.strptime(monthword,'%b').tm_mon\n",
    "\n",
    "                    year = d.strftime('%Y')\n",
    "\n",
    "                eachnewrow.append(weekday) #weekday\n",
    "                eachnewrow.append(day) #day \n",
    "                eachnewrow.append(month) #month\n",
    "                eachnewrow.append(year) #year\n",
    "\n",
    "                eachnewrow.append(row[11]) #revenue\n",
    "                eachnewrow.append(row[12]) #runtime\n",
    "                #row[13] spoken_languages removed  \n",
    "                #row[14] status removed \n",
    "                #row[15] tagline removed   \n",
    "                eachnewrow.append(row[16]) #title\n",
    "                eachnewrow.append(row[17]) #vote_average\n",
    "                eachnewrow.append(row[18]) #vote_count                  \n",
    "\n",
    "                WR = (float(row[18]) / (float(row[18])+25000)) * float(row[17]) + (25000 / (float(row[18]) + 25000)) * 7.0            \n",
    "\n",
    "                eachnewrow.append(WR) #weighted_rating\n",
    "\n",
    "                rowslist.append(eachnewrow)\n",
    "\n",
    "                line_count += 1\n",
    "        except Exception as e:\n",
    "            print(f'Row: {line_count} has Exception')    \n",
    "            line_count += 1          \n",
    "    print(f'Processed {line_count} lines.')   \n",
    "                  \n",
    "genresdictionary = corpora.Dictionary(genreslist)\n",
    "token_to_id_genres = genresdictionary.token2id                \n",
    "\n",
    "#productioncompaniesdictionary = corpora.Dictionary(productioncompanieslist)\n",
    "#token_to_id_productioncompanies = productioncompaniesdictionary.token2id\n",
    "                  \n",
    "#productioncountriesdictionary = corpora.Dictionary(productioncountrieslist)\n",
    "#token_to_id_productioncountries = productioncountriesdictionary.token2id   \n",
    "\n",
    "def assigningValues(vector, listofzeros):\n",
    "    for counter, value in enumerate(vector): \n",
    "        index = 0       \n",
    "        for value2 in listofzeros:                      \n",
    "            if index == value[0]:\n",
    "                listofzeros[index] = value[1]    \n",
    "            index += 1\n",
    "                  \n",
    "    return listofzeros\n",
    "                  \n",
    "#write to file\n",
    "with open('processed_tmdb_10000_movies.csv', mode='w', newline='', encoding='utf-8') as movies_file: #change accordingly\n",
    "    writer2 = csv.writer(movies_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    writer2.writerow(['budget'] + list(genresdictionary.values()) + ['id', 'popularity', 'production_companies', 'production_countries'] \n",
    "        #+ list(productioncompaniesdictionary.values()) + list(productioncountriesdictionary.values()) \n",
    "        + ['weekday', 'day', 'month', 'year', 'revenue', 'runtime', 'title', 'vote_average', 'vote_count', 'weighted_rating'])              \n",
    "    \n",
    "    for eachrow in rowslist:\n",
    "        listofzerosgenres = [0] * len(token_to_id_genres)\n",
    "        #listofzerosproductioncompanies = [0] * len(token_to_id_productioncompanies)\n",
    "        #listofzerosproductioncountries = [0] * len(token_to_id_productioncountries)                   \n",
    "                  \n",
    "        vec_genres = genresdictionary.doc2bow(eachrow[1])\n",
    "        #vec_productioncompanies = productioncompaniesdictionary.doc2bow(eachrow[4])\n",
    "        #vec_productioncountries = productioncountriesdictionary.doc2bow(eachrow[5])                   \n",
    "\n",
    "        listofzerosgenres = assigningValues(vec_genres, listofzerosgenres)\n",
    "        #listofzerosproductioncompanies = assigningValues(vec_productioncompanies, listofzerosproductioncompanies)\n",
    "        #listofzerosproductioncountries = assigningValues(vec_productioncountries, listofzerosproductioncountries)\n",
    "\n",
    "        writer2.writerow(eachrow[0:1] + listofzerosgenres + eachrow[2:6] \n",
    "            #+ listofzerosproductioncompanies + listofzerosproductioncountries \n",
    "            + eachrow[6:16])\n",
    "                  \n",
    "    print('\\nOutput Success!')                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Separating JSON Data into Columns (Credits)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are id, cast, crew\n",
      "Processed 6 lines.\n",
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import csv, json, gensim\n",
    "from gensim import corpora\n",
    "\n",
    "rowslist = []\n",
    "departmentslist = []\n",
    "jobtitleslist = []\n",
    "\n",
    "#read file\n",
    "with open('tmdb_10000_credits.csv', encoding='utf-8') as csv_file: #change accordingly\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            if line_count == 0:\n",
    "                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else: #if line_count != 5:\n",
    "                eachnewrow = []\n",
    "                departments = []\n",
    "                jobtitles = []\n",
    "\n",
    "                malecastsnum = 0\n",
    "                femalecastsnum = 0\n",
    "                unknowngendercastsnum = 0    \n",
    "                totalcasts = 0\n",
    "\n",
    "                malecrewsnum = 0\n",
    "                femalecrewsnum = 0\n",
    "                unknowngendercrewsnum = 0\n",
    "                totalcrews = 0\n",
    "\n",
    "                eachnewrow.append(row[0]) #id\n",
    "\n",
    "                #handle json casts\n",
    "                jsonstring = row[1]\n",
    "\n",
    "                jsonobj = json.loads(jsonstring)\n",
    "\n",
    "                for jsonelement in jsonobj:\n",
    "                    gender = jsonelement['gender']       \n",
    "                    if gender == 0:\n",
    "                      unknowngendercastsnum += 1\n",
    "                    elif gender == 1:\n",
    "                      femalecastsnum += 1\n",
    "                    elif gender == 2:\n",
    "                      malecastsnum += 1\n",
    "\n",
    "                    totalcasts += 1\n",
    "\n",
    "                eachnewrow.append(malecastsnum) #malecastsnum\n",
    "                eachnewrow.append(femalecastsnum) #femalecastsnum                  \n",
    "                eachnewrow.append(unknowngendercastsnum) #unknowngendercastsnum \n",
    "                eachnewrow.append(totalcasts) #totalcasts                   \n",
    "\n",
    "                #handle json crews              \n",
    "                jsonstring2 = row[2]\n",
    "\n",
    "                jsonobj2 = json.loads(jsonstring2)\n",
    "\n",
    "                for jsonelement in jsonobj2:\n",
    "                    gender = jsonelement['gender']       \n",
    "                    if gender == 0:\n",
    "                      unknowngendercrewsnum += 1\n",
    "                    elif gender == 1:\n",
    "                      femalecrewsnum += 1\n",
    "                    elif gender == 2:\n",
    "                      malecrewsnum += 1  \n",
    "\n",
    "                    totalcrews += 1\n",
    "\n",
    "                    department = jsonelement['department']\n",
    "                    departments.append(department.lower())         \n",
    "\n",
    "                    jobtitle = jsonelement['job']\n",
    "                    jobtitles.append(jobtitle.lower())                    \n",
    "\n",
    "                eachnewrow.append(malecrewsnum) #malecastsnum\n",
    "                eachnewrow.append(femalecrewsnum) #femalecastsnum                  \n",
    "                eachnewrow.append(unknowngendercrewsnum) #unknowngendercastsnum                   \n",
    "                eachnewrow.append(totalcrews) #totalcrews  \n",
    "\n",
    "                eachnewrow.append(departments) #departments\n",
    "                departmentslist.append(departments)  \n",
    "\n",
    "                eachnewrow.append(jobtitles) #jobtitles\n",
    "                jobtitleslist.append(jobtitles)\n",
    "\n",
    "                rowslist.append(eachnewrow)\n",
    "\n",
    "                line_count += 1\n",
    "        except Exception as e:\n",
    "            print(f'Row: {line_count} has Exception')    \n",
    "            line_count += 1   \n",
    "\n",
    "    print(f'Processed {line_count} lines.')\n",
    "                  \n",
    "departmentsdictionary = corpora.Dictionary(departmentslist)\n",
    "token_to_id_departments = departmentsdictionary.token2id\n",
    "#print(f'Dictionary for Departments: {token_to_id_departments}') \n",
    "#print(f'\\nNo. of Departments: {len(token_to_id_departments)}')\n",
    "                  \n",
    "jobtitlesdictionary = corpora.Dictionary(jobtitleslist)\n",
    "token_to_id_jobtitles = jobtitlesdictionary.token2id\n",
    "#print(f'Dictionary for Job Titles: {token_to_id_jobtitles}')        \n",
    "#print(f'No. of Job Titles: {len(token_to_id_jobtitles)}')                   \n",
    "\n",
    "def assigningValues(vector, listofzeros):\n",
    "    for counter, value in enumerate(vector): \n",
    "        index = 0       \n",
    "        for value2 in listofzeros:                      \n",
    "            if index == value[0]:\n",
    "                listofzeros[index] = value[1]    \n",
    "            index += 1\n",
    "                  \n",
    "    return listofzeros                  \n",
    "                  \n",
    "#write to file\n",
    "with open('processed_tmdb_10000_credits.csv', mode='w', newline='', encoding='utf-8') as credits_file: #change accordingly\n",
    "    writer = csv.writer(credits_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    writer.writerow(['id', 'malecastsnum', 'femalecastsnum', 'unknowngendercastsnum', 'totalcasts', 'malecrewsnum', 'femalecrewsnum', 'unknowngendercrewsnum', 'totalcrews'] \n",
    "        + list(departmentsdictionary.values()) + list(jobtitlesdictionary.values()))              \n",
    "    \n",
    "    for eachrow in rowslist:\n",
    "        listofzerosdepartments = [0] * len(token_to_id_departments)\n",
    "        listofzerosjobtitles = [0] * len(token_to_id_jobtitles)                         \n",
    "                  \n",
    "        vec_departments = departmentsdictionary.doc2bow(eachrow[9])\n",
    "        vec_jobtitles = jobtitlesdictionary.doc2bow(eachrow[10])   \n",
    "\n",
    "        listofzerosdepartments = assigningValues(vec_departments, listofzerosdepartments)\n",
    "        listofzerosjobtitles = assigningValues(vec_jobtitles, listofzerosjobtitles)\n",
    "\n",
    "        writer.writerow(eachrow[0:9] + listofzerosdepartments + listofzerosjobtitles)\n",
    "\n",
    "    print('\\nOutput Success!')\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Merging Two Files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv(\"processed_tmdb_10000_movies.csv\") #change accordingly\n",
    "credits = pd.read_csv(\"processed_tmdb_10000_credits.csv\") #change accordingly\n",
    "merged = pd.merge(movies, credits, left_on=['id'],\n",
    "                   right_on=['id'], \n",
    "                   how='left')\n",
    "merged.to_csv(\"processed_tmdb_data.csv\", index=False)\n",
    "\n",
    "print('\\nOutput Success!')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Append New Processed Data to Previous Merged File</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4804 lines.\n",
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('main_processed_tmdb_data.csv', mode='a', newline='', encoding='utf-8') as main_file:\n",
    "    writer3 = csv.writer(main_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    with open('processed_tmdb_data.csv', mode='r', newline='') as new_file:\n",
    "        csv_reader = csv.reader(new_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                writer3.writerow(row)\n",
    "                line_count += 1\n",
    "            \n",
    "    print(f'Processed {line_count} lines.')\n",
    "    \n",
    "    print('\\nOutput Success!')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
