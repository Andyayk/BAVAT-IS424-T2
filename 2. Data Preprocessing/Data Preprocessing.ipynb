{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Separating JSON Data into Columns (Movies)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are budget, genres, homepage, id, original_language, original_title, overview, popularity, production_companies, production_countries, release_date, revenue, runtime, spoken_languages, status, tagline, title, vote_average, vote_count\n",
      "Processed 5 lines.\n",
      "  budget comedy horror documentary      id attack casey charismat defend dojo  \\\n",
      "0      0      1      0           0  480001      1     1         1      1    1   \n",
      "1      0      0      1           0  480002      0     0         0      0    0   \n",
      "2      0      0      0           0  480003      0     0         0      0    0   \n",
      "3      0      0      0           1  480004      0     0         0      0    0   \n",
      "\n",
      "        ...       day month  year revenue runtime           status  \\\n",
      "0       ...        10     3  2019       0     104  Post Production   \n",
      "1       ...        01    10  2017       0      46         Released   \n",
      "2       ...        14    10  2008       0      20         Released   \n",
      "3       ...        14     3  2008       0      20         Released   \n",
      "\n",
      "                                               title vote_average vote_count  \\\n",
      "0                            The Art of Self-Defense            0          0   \n",
      "1                                      The Cornfield            0          0   \n",
      "2  Dreaming with Scissors: Hitchcock, Surrealism ...            0          0   \n",
      "3  Guilt by Association: Psychoanalyzing 'Spellbo...            0          0   \n",
      "\n",
      "  weighted_rating  \n",
      "0             7.0  \n",
      "1             7.0  \n",
      "2             7.0  \n",
      "3             7.0  \n",
      "\n",
      "[4 rows x 66 columns]\n",
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import csv, json, gensim, datetime, time\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "\n",
    "rowslist = []\n",
    "genreslist = []\n",
    "productioncompanieslist = []\n",
    "overviewlist = []\n",
    "\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def readJSON(row, rownumber, list, keyword):\n",
    "    jsonstring = row[rownumber]\n",
    "\n",
    "    jsonobj = json.loads(jsonstring)\n",
    "\n",
    "    for jsonelement in jsonobj:\n",
    "        keywordelement = jsonelement[keyword]       \n",
    "        list.append(keywordelement.lower()) \n",
    "    \n",
    "    return list\n",
    "    \n",
    "def processText(row, rownumber1, rownumber2, list):\n",
    "    text = row[rownumber1].split(\" \") + row[rownumber2].split(\" \") #contains overview and tagline\n",
    "    \n",
    "    text1 = [w.lower() for w in text]\n",
    "    text2 = [w for w in text1 if re.search('^[a-z]+$', w)]\n",
    "    text3 = [w for w in text2 if w not in stop_list]\n",
    "    text4 = [stemmer.stem(w) for w in text3]  \n",
    "    \n",
    "    list = text4\n",
    "    \n",
    "    return list\n",
    "    \n",
    "#read file\n",
    "with open('tmdb_All_movies.csv', encoding='utf-8') as csv_file: #change accordingly\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        try:        \n",
    "            if line_count == 0:\n",
    "                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            elif line_count != 5:\n",
    "                eachnewrow = []\n",
    "                genres = []\n",
    "                productioncompanies = []\n",
    "                productioncountries = []\n",
    "                overview = []\n",
    "\n",
    "                eachnewrow.append(row[0]) #budget\n",
    "\n",
    "                if row[1] != \"\":\n",
    "                    #handle json genres\n",
    "                    genres = readJSON(row, 1, genres, 'name')\n",
    "\n",
    "                eachnewrow.append(genres) #genres\n",
    "                genreslist.append(genres)\n",
    "\n",
    "                #row[2] homepage removed\n",
    "                eachnewrow.append(row[3]) #id\n",
    "\n",
    "                #row[4] original_language removed\n",
    "                #row[5] original_title removed  \n",
    "                                            \n",
    "                #handle overview\n",
    "                overview = processText(row, 6, 15,overview)\n",
    "\n",
    "                eachnewrow.append(overview)\n",
    "                overviewlist.append(overview)\n",
    "\n",
    "                eachnewrow.append(row[7]) #popularity                  \n",
    "                \n",
    "                if row[8] != \"\":\n",
    "                    #handle json productioncompanies\n",
    "                    productioncompanies = readJSON(row, 8, productioncompanies, 'name')\n",
    "\n",
    "                eachnewrow.append(productioncompanies) #productioncompanies\n",
    "                productioncompanieslist.append(productioncompanies)                  \n",
    "\n",
    "                #row[9] productioncountries\n",
    "\n",
    "                weekday = \"\"\n",
    "                day = \"\"\n",
    "                month = \"\"\n",
    "                year = \"\"                 \n",
    "\n",
    "                #handle releasedate \n",
    "                if row[10] != \"\":\n",
    "                    d = datetime.datetime.strptime(row[10] ,'%Y-%m-%d')\n",
    "\n",
    "                    weekdayword = d.strftime('%a')\n",
    "                    weekday = time.strptime(weekdayword, '%a').tm_wday + 1\n",
    "\n",
    "                    day = d.strftime('%d')\n",
    "\n",
    "                    monthword = d.strftime('%b')\n",
    "                    month = time.strptime(monthword,'%b').tm_mon\n",
    "\n",
    "                    year = d.strftime('%Y')\n",
    "\n",
    "                eachnewrow.append(weekday) #weekday\n",
    "                eachnewrow.append(day) #day \n",
    "                eachnewrow.append(month) #month\n",
    "                eachnewrow.append(year) #year\n",
    "\n",
    "                eachnewrow.append(row[11]) #revenue\n",
    "                eachnewrow.append(row[12]) #runtime\n",
    "                #row[13] spoken_languages removed  \n",
    "                eachnewrow.append(row[14]) #status                      \n",
    "                #row[15] tagline added to overview\n",
    "                eachnewrow.append(row[16]) #title\n",
    "                eachnewrow.append(row[17]) #vote_average\n",
    "                eachnewrow.append(row[18]) #vote_count                  \n",
    "\n",
    "                WR = (float(row[18]) / (float(row[18])+25000)) * float(row[17]) + (25000 / (float(row[18]) + 25000)) * 7.0            \n",
    "\n",
    "                eachnewrow.append(WR) #weighted_rating\n",
    "\n",
    "                rowslist.append(eachnewrow)\n",
    "\n",
    "                line_count += 1\n",
    "        except Exception as e:\n",
    "            print(f'Row: {line_count} has Exception' + str(e))    \n",
    "            line_count += 1          \n",
    "    print(f'Processed {line_count} lines.')   \n",
    "                  \n",
    "genresdictionary = corpora.Dictionary(genreslist)\n",
    "token_to_id_genres = genresdictionary.token2id                \n",
    "\n",
    "overviewdictionary = corpora.Dictionary(overviewlist)\n",
    "token_to_id_overview = overviewdictionary.token2id                            \n",
    "                      \n",
    "productioncompaniesdictionary = corpora.Dictionary(productioncompanieslist)\n",
    "token_to_id_productioncompanies = productioncompaniesdictionary.token2id                  \n",
    "                      \n",
    "def assigningValues(vector, listofzeros):\n",
    "    for counter, value in enumerate(vector): \n",
    "        index = 0       \n",
    "        for value2 in listofzeros:                      \n",
    "            if index == value[0]:\n",
    "                listofzeros[index] = value[1]    \n",
    "            index += 1\n",
    "                  \n",
    "    return listofzeros\n",
    "\n",
    "tablecolumns = ['budget'] + list(genresdictionary.values()) + ['id'] + list(overviewdictionary.values()) + ['popularity'] + list(productioncompaniesdictionary.values()) + ['weekday', 'day', 'month', 'year', 'revenue', 'runtime', 'status', 'title', 'vote_average', 'vote_count', 'weighted_rating']\n",
    "\n",
    "tablerows = []\n",
    "for eachrow in rowslist:\n",
    "    listofzerosgenres = [0] * len(token_to_id_genres)\n",
    "    listofzerosoverview = [0] * len(token_to_id_overview)                          \n",
    "    listofzerosproductioncompanies = [0] * len(token_to_id_productioncompanies)                    \n",
    "\n",
    "    vec_genres = genresdictionary.doc2bow(eachrow[1])\n",
    "    vec_overview = overviewdictionary.doc2bow(eachrow[3])                         \n",
    "    vec_productioncompanies = productioncompaniesdictionary.doc2bow(eachrow[5])                     \n",
    "\n",
    "    listofzerosgenres = assigningValues(vec_genres, listofzerosgenres)\n",
    "    listofzerosoverview = assigningValues(vec_overview, listofzerosoverview)                      \n",
    "    listofzerosproductioncompanies = assigningValues(vec_productioncompanies, listofzerosproductioncompanies)                      \n",
    "    \n",
    "    tablerows.append(eachrow[0:1] + listofzerosgenres + eachrow[2:3] + listofzerosoverview + eachrow[4:5] \n",
    "                     + listofzerosproductioncompanies + eachrow[6:17])\n",
    "\n",
    "df = pd.DataFrame(np.array(tablerows), columns=tablecolumns)                      \n",
    "print(df.head(10))      \n",
    "#write to file\n",
    "\"\"\"\"\n",
    "with open('processed_tmdb_movies.csv', mode='w', newline='', encoding='utf-8') as movies_file: #change accordingly\n",
    "    writer2 = csv.writer(movies_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    writer2.writerow(['budget'] + list(genresdictionary.values()) + ['id'] + list(overviewdictionary.values()) + ['popularity'] \n",
    "        + list(productioncompaniesdictionary.values()) \n",
    "        + ['weekday', 'day', 'month', 'year', 'revenue', 'runtime', 'status', 'title', 'vote_average', 'vote_count', 'weighted_rating'])              \n",
    "    \n",
    "    for eachrow in rowslist:\n",
    "        listofzerosgenres = [0] * len(token_to_id_genres)\n",
    "        listofzerosoverview = [0] * len(token_to_id_overview)                          \n",
    "        listofzerosproductioncompanies = [0] * len(token_to_id_productioncompanies)                    \n",
    "                  \n",
    "        vec_genres = genresdictionary.doc2bow(eachrow[1])\n",
    "        vec_overview = overviewdictionary.doc2bow(eachrow[3])                         \n",
    "        vec_productioncompanies = productioncompaniesdictionary.doc2bow(eachrow[5])                     \n",
    "\n",
    "        listofzerosgenres = assigningValues(vec_genres, listofzerosgenres)\n",
    "        listofzerosoverview = assigningValues(vec_overview, listofzerosoverview)                      \n",
    "        listofzerosproductioncompanies = assigningValues(vec_productioncompanies, listofzerosproductioncompanies)\n",
    "\n",
    "        writer2.writerow(eachrow[0:1] + listofzerosgenres + eachrow[2:3] + listofzerosoverview + eachrow[4:5] \n",
    "        + listofzerosproductioncompanies + eachrow[6:17])\n",
    "\"\"\"\n",
    "print('\\nOutput Success!')                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Separating JSON Data into Columns (Credits)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are id, cast, crew\n",
      "Processed 5 lines.\n",
      "       id alessandro nivola david zellner imogen poots jason burkey  \\\n",
      "0  480001                 1             1            1            1   \n",
      "1  480002                 0             0            0            0   \n",
      "2  480003                 0             0            0            0   \n",
      "3  480004                 0             0            0            0   \n",
      "\n",
      "  jesse eisenberg phillip andre botello steve terada george bonilla  \\\n",
      "0               1                     1            1              0   \n",
      "1               0                     0            0              1   \n",
      "2               0                     0            0              0   \n",
      "3               0                     0            0              0   \n",
      "\n",
      "  bruce scivally    ...    robert yanal rudy behlmer scott mcisaac  \\\n",
      "0              0    ...               0            0             0   \n",
      "1              0    ...               0            0             0   \n",
      "2              0    ...               0            0             0   \n",
      "3              1    ...               1            1             1   \n",
      "\n",
      "  shad meshad stephen rebello thomas schatz riley stearns george bonilla  \\\n",
      "0           0               0             0             1              0   \n",
      "1           0               0             0             0              1   \n",
      "2           0               0             0             0              0   \n",
      "3           1               1             1             0              0   \n",
      "\n",
      "  lisa van eyssen john cork  \n",
      "0               0         0  \n",
      "1               0         0  \n",
      "2               1         0  \n",
      "3               0         1  \n",
      "\n",
      "[4 rows x 23 columns]\n",
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import csv, json, gensim\n",
    "from gensim import corpora\n",
    "\n",
    "rowslist = []\n",
    "castslist = []\n",
    "crewslist = []\n",
    "\n",
    "#read file\n",
    "with open('tmdb_All_credits.csv', encoding='utf-8') as csv_file: #change accordingly\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            if line_count == 0:\n",
    "                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            elif line_count != 5:\n",
    "                eachnewrow = []\n",
    "                casts = []\n",
    "                crews = []\n",
    "\n",
    "                eachnewrow.append(row[0]) #id\n",
    "\n",
    "                #handle json casts\n",
    "                if row[1] != \"\":                      \n",
    "                    jsonstring = row[1]\n",
    "\n",
    "                    jsonobj = json.loads(jsonstring)\n",
    "\n",
    "                    for jsonelement in jsonobj:\n",
    "                        cast = jsonelement['name']       \n",
    "                        casts.append(cast.lower())\n",
    "\n",
    "                eachnewrow.append(casts) #casts\n",
    "                castslist.append(casts)\n",
    "\n",
    "                #handle json crews \n",
    "                if row[2] != \"\":                       \n",
    "                    jsonstring2 = row[2]\n",
    "\n",
    "                    jsonobj2 = json.loads(jsonstring2)\n",
    "\n",
    "                    for jsonelement in jsonobj2:\n",
    "                        job = jsonelement['job']\n",
    "                        if job == \"Director\":\n",
    "                            crew = jsonelement['name']       \n",
    "                            crews.append(crew.lower())\n",
    "\n",
    "                eachnewrow.append(crews) #crews\n",
    "                crewslist.append(crews)         \n",
    "\n",
    "                rowslist.append(eachnewrow)\n",
    "\n",
    "                line_count += 1\n",
    "        except Exception as e:\n",
    "            print(f'Row: {line_count} has Exception' + str(e))    \n",
    "            line_count += 1   \n",
    "\n",
    "    print(f'Processed {line_count} lines.')\n",
    "                  \n",
    "castsdictionary = corpora.Dictionary(castslist)\n",
    "token_to_id_casts = castsdictionary.token2id\n",
    "                  \n",
    "crewsdictionary = corpora.Dictionary(crewslist)\n",
    "token_to_id_crews = crewsdictionary.token2id                  \n",
    "\n",
    "def assigningValues(vector, listofzeros):\n",
    "    for counter, value in enumerate(vector): \n",
    "        index = 0       \n",
    "        for value2 in listofzeros:                      \n",
    "            if index == value[0]:\n",
    "                listofzeros[index] = value[1]    \n",
    "            index += 1\n",
    "                  \n",
    "    return listofzeros                  \n",
    "\n",
    "tablecolumns2 = ['id'] + list(castsdictionary.values()) + list(crewsdictionary.values())\n",
    "                      \n",
    "tablerows2 = []        \n",
    "                      \n",
    "for eachrow in rowslist:\n",
    "    listofzeroscasts = [0] * len(token_to_id_casts)\n",
    "    listofzeroscrews = [0] * len(token_to_id_crews)                         \n",
    "\n",
    "    vec_casts = castsdictionary.doc2bow(eachrow[1])\n",
    "    vec_crews = crewsdictionary.doc2bow(eachrow[2])   \n",
    "\n",
    "    listofzeroscasts = assigningValues(vec_casts, listofzeroscasts)\n",
    "    listofzeroscrews = assigningValues(vec_crews, listofzeroscrews)\n",
    "\n",
    "    tablerows2.append(eachrow[0:1] + listofzeroscasts + listofzeroscrews)\n",
    "                      \n",
    "df2 = pd.DataFrame(np.array(tablerows2), columns=tablecolumns2)                      \n",
    "print(df2.head(10))                        \n",
    "\"\"\"                     \n",
    "#write to file\n",
    "with open('processed_tmdb_credits.csv', mode='w', newline='', encoding='utf-8') as credits_file: #change accordingly\n",
    "    writer = csv.writer(credits_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    writer.writerow(['id'] + list(castsdictionary.values()) + list(crewsdictionary.values()))              \n",
    "    \n",
    "    for eachrow in rowslist:\n",
    "        listofzeroscasts = [0] * len(token_to_id_casts)\n",
    "        listofzeroscrews = [0] * len(token_to_id_crews)                         \n",
    "                  \n",
    "        vec_casts = castsdictionary.doc2bow(eachrow[1])\n",
    "        vec_crews = crewsdictionary.doc2bow(eachrow[2])   \n",
    "\n",
    "        listofzeroscasts = assigningValues(vec_casts, listofzeroscasts)\n",
    "        listofzeroscrews = assigningValues(vec_crews, listofzeroscrews)\n",
    "\n",
    "        writer.writerow(eachrow[0:1] + listofzeroscasts + listofzeroscrews)\n",
    "\"\"\"\n",
    "print('\\nOutput Success!')                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Merging Two Files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  budget comedy horror documentary      id attack casey charismat defend dojo  \\\n",
      "0      0      1      0           0  480001      1     1         1      1    1   \n",
      "1      0      0      1           0  480002      0     0         0      0    0   \n",
      "2      0      0      0           0  480003      0     0         0      0    0   \n",
      "3      0      0      0           1  480004      0     0         0      0    0   \n",
      "\n",
      "     ...    robert yanal rudy behlmer scott mcisaac shad meshad  \\\n",
      "0    ...               0            0             0           0   \n",
      "1    ...               0            0             0           0   \n",
      "2    ...               0            0             0           0   \n",
      "3    ...               1            1             1           1   \n",
      "\n",
      "  stephen rebello thomas schatz riley stearns george bonilla lisa van eyssen  \\\n",
      "0               0             0             1              0               0   \n",
      "1               0             0             0              1               0   \n",
      "2               0             0             0              0               1   \n",
      "3               1             1             0              0               0   \n",
      "\n",
      "  john cork  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         1  \n",
      "\n",
      "[4 rows x 88 columns]\n",
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df3 = df.join(df2.set_index('id'), on='id')\n",
    "print(df3.head(10)) \n",
    "\"\"\"\n",
    "movies = pd.read_csv(\"processed_tmdb_movies.csv\") #change accordingly\n",
    "credits = pd.read_csv(\"processed_tmdb_credits.csv\") #change accordingly\n",
    "merged = pd.merge(movies, credits, left_on=['id'],\n",
    "                   right_on=['id'], \n",
    "                   how='left')\n",
    "merged.to_csv(\"processed_tmdb_data.csv\", index=False)\n",
    "\"\"\"\n",
    "print('\\nOutput Success!')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Append New Processed Data to Previous Merged File</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4804 lines.\n",
      "\n",
      "Output Success!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('main_processed_tmdb_data.csv', mode='a', newline='', encoding='utf-8') as main_file:\n",
    "    writer3 = csv.writer(main_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    with open('processed_tmdb_data.csv', mode='r', newline='') as new_file:\n",
    "        csv_reader = csv.reader(new_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                writer3.writerow(row)\n",
    "                line_count += 1\n",
    "            \n",
    "    print(f'Processed {line_count} lines.')\n",
    "    \n",
    "    print('\\nOutput Success!')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
